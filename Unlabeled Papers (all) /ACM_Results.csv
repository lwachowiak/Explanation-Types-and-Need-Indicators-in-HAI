"Item type","Authors","Title","Journal","Publication year","Volume","Issue","Pages","Publisher","Address","Proceedings title","Conference location","Date published","ISBN","ISSN","URLs","DOI","Abstract","Keywords","Notes","Series"
"Conference Paper","Mosca F,Such JM","ELVIRA: An Explainable Agent for Value and Utility-Driven Multiuser Privacy","","2021","","","916–924","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems","Virtual Event, United Kingdom","2021","9781450383073","","","","Online social networks fail to support users to adequately share co-owned content, which leads to privacy violations. Scholars proposed collaborative mechanisms to support users, but they did not satisfy one or more requirements needed according to empirical evidence in this domain, such as explainability, role-agnosticism, adaptability, and being utility- and value-driven. We present ELVIRA, an agent that supports multiuser privacy, whose design meets all these requirements. By considering the sharing preferences and the moral values of users, ELVIRA identifies the optimal sharing policy. Furthermore, ELVIRA justifies the optimality of the solution through explanations based on argumentation. We prove via simulations that ELVIRA provides solutions with the best trade-off between individual utility and value adherence. We also show through a user study that ELVIRA suggests solutions that are more acceptable than existing approaches and that its explanations are also more satisfactory.","explainable agents, practical reasoning, multiuser privacy, human-agent interaction, value-based agents","","AAMAS '21"
"Conference Paper","Anjomshoae S,Najjar A,Calvaresi D,Främling K","Explainable Agents and Robots: Results from a Systematic Literature Review","","2019","","","1078–1088","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems","Montreal QC, Canada","2019","9781450363099","","","","Humans are increasingly relying on complex systems that heavily adopts Artificial Intelligence (AI) techniques. Such systems are employed in a growing number of domains, and making them explainable is an impelling priority. Recently, the domain of eXplainable Artificial Intelligence (XAI) emerged with the aims of fostering transparency and trustworthiness. Several reviews have been conducted. Nevertheless, most of them deal with data-driven XAI to overcome the opaqueness of black-box algorithms. Contributions addressing goal-driven XAI (e.g., explainable agency for robots and agents) are still missing. This paper aims at filling this gap, proposing a Systematic Literature Review. The main findings are (i) a considerable portion of the papers propose conceptual studies, or lack evaluations or tackle relatively simple scenarios; (ii) almost all of the studied papers deal with robots/agents explaining their behaviors to the human users, and very few works addressed inter-robot (inter-agent) explainability. Finally, (iii) while providing explanations to non-expert users has been outlined as a necessity, only a few works addressed the issues of personalization and context-awareness.","goal-based XAI, human-robot interaction, explainable AI, autonomous agents","","AAMAS '19"
"Conference Paper","Das D,Banerjee S,Chernova S","Explainable AI for Robot Failures: Generating Explanations That Improve User Assistance in Fault Recovery","","2021","","","351–360","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction","Boulder, CO, USA","2021","9781450382892","","https://doi.org/10.1145/3434073.3444657;http://dx.doi.org/10.1145/3434073.3444657","10.1145/3434073.3444657","With the growing capabilities of intelligent systems, the integration of robots in our everyday life is increasing. However, when interacting in such complex human environments, the occasional failure of robotic systems is inevitable. The field of explainable AI has sought to make complex-decision making systems more interpretable but most existing techniques target domain experts. On the contrary, in many failure cases, robots will require recovery assistance from non-expert users. In this work, we introduce a new type of explanation, εerr, that explains the cause of an unexpected failure during an agent's plan execution to non-experts. In order for error explanations to be meaningful, we investigate what types of information within a set of hand-scripted explanations are most helpful to non-experts for failure and solution identification. Additionally, we investigate how such explanations can be autonomously generated, extending an existing encoder-decoder model, and generalized across environments. We investigate such questions in the context of a robot performing a pick-and-place manipulation task in the home environment. Our results show that explanations capturing the context of a failure and history of past actions, are the most effective for failure and solution identification among non-experts. Furthermore, through a second user evaluation, we verify that our model-generated explanations can generalize to an unseen office environment, and are just as effective as the hand-scripted explanations.","explainable ai, fault recovery","","HRI '21"
"Conference Paper","Kwiatkowski J,Ou L,Chang YC,Lin CT","Explainable Hybrid CNN and FNN Approach Applied on Robotic Wall-Following Behaviour Learning","","2022","","","623–628","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2021 4th International Conference on Artificial Intelligence and Pattern Recognition","Xiamen, China","2022","9781450384087","","https://doi.org/10.1145/3488933.3489026;http://dx.doi.org/10.1145/3488933.3489026","10.1145/3488933.3489026","Fuzzy Neural Network (FNN) applied to robotic control tasks has proved to be effective by previous researchers. However, FNN has an inherent deficiency in dealing with inputs of large dimensions, such as images. Therefore, this research utilizes a Convolutional Neural Network (CNN) model to convert image into distance values and delivers these values to FNN based robot controller as inputs. The proposed hybrid CNN+FNN are tested with both a regression model and a multi-task model. Results show that the multi-task method performs better with less information loss from input images. This paper also proved that the proposed hybrid approach can be generalized into an unknown robotic simulation environment and performs better than its FNN counterpart. By utilizing state of the art explainable analysis method, both the CNN part and the FNN part of the hybrid approach can be explained in a human-understandable way.","Fuzzy System, Robotic Navigation, Additional Key Words and Phrases: Explainable AI","","AIPR '21"
"Conference Paper","Tabrez A,Hayes B","Improving Human-Robot Interaction through Explainable Reinforcement Learning","","2020","","","751–753","IEEE Press","Daegu, Republic of Korea","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","","2020","9781538685556","","","","Gathering the most informative data from humans without overloading them remains an active research area in AI, and is closely coupled with the problems of determining how and when information should be communicated to others [12]. Current decision support systems (DSS) are still overly simple and static, and cannot adapt to changing environments we expect to deploy in modern systems [3], [4], [9], [11]. They are intrinsically limited in their ability to explain rationale versus merely listing their future behaviors, limiting a human's understanding of the system [2], [7]. Most probabilistic assessments of a task are conveyed after the task/skill is attempted rather than before [10], [14], [16]. This limits failure recovery and danger avoidance mechanisms. Existing work on predicting failures relies on sensors to accurately detect explicitly annotated and learned failure modes [13]. As such, important non-obvious pieces of information for assessing appropriate trust and/or course-of-action (COA) evaluation in collaborative scenarios can go overlooked, while irrelevant information may instead be provided that increases clutter and mental workload. Understanding how AI models arrive at specific decisions is a key principle of trust [8]. Therefore, it is critically important to develop new strategies for anticipating, communicating, and explaining justifications and rationale for AI driven behaviors via contextually appropriate semantics.","","","HRI '19"
"Journal Article","Han Z,Phillips E,Yanco HA","The Need for Verbal Robot Explanations and How People Would Like a Robot to Explain Itself","J.  Hum. -Robot Interact.","2021","10","4","","Association for Computing Machinery","New York, NY, USA","","","2021-09","","","https://doi.org/10.1145/3469652;http://dx.doi.org/10.1145/3469652","10.1145/3469652","Although non-verbal cues such as arm movement and eye gaze can convey robot intention, they alone may not provide enough information for a human to fully understand a robot’s behavior. To better understand how to convey robot intention, we conducted an experiment (N = 366) investigating the need for robots to explain, and the content and properties of a desired explanation such as timing, engagement importance, similarity to human explanations, and summarization. Participants watched a video where the robot was commanded to hand an almost-reachable cup and one of six reactions intended to show the unreachability : doing nothing (No Cue), turning its head to the cup (Look), or turning its head to the cup with the addition of repeated arm movement pointed towards the cup (Look & Point), and each of these with or without a Headshake. The results indicated that participants agreed robot behavior should be explained across all conditions, in situ, in a similar manner as what human explain, and provide concise summaries and respond to only a few follow-up questions by participants. Additionally, we replicated the study again with N = 366 participants after a 15-month span and all major conclusions still held.","behavior explanation, system transparency, Robot explanation","",""
"Journal Article","Han Z,Giger D,Allspaw J,Lee MS,Admoni H,Yanco HA","Building the Foundation of Robot Explanation Generation Using Behavior Trees","J.  Hum. -Robot Interact.","2021","10","3","","Association for Computing Machinery","New York, NY, USA","","","2021-07","","","https://doi.org/10.1145/3457185;http://dx.doi.org/10.1145/3457185","10.1145/3457185","As autonomous robots continue to be deployed near people, robots need to be able to explain their actions. In this article, we focus on organizing and representing complex tasks in a way that makes them readily explainable. Many actions consist of sub-actions, each of which may have several sub-actions of their own, and the robot must be able to represent these complex actions before it can explain them. To generate explanations for robot behavior, we propose using Behavior Trees (BTs), which are a powerful and rich tool for robot task specification and execution. However, for BTs to be used for robot explanations, their free-form, static structure must be adapted. In this work, we add structure to previously free-form BTs by framing them as a set of semantic sets goal, subgoals, steps, actions and subsequently build explanation generation algorithms that answer questions seeking causal information about robot behavior. We make BTs less static with an algorithm that inserts a subgoal that satisfies all dependencies. We evaluate our BTs for robot explanation generation in two domains: a kitting task to assemble a gearbox, and a taxi simulation. Code for the behavior trees (in XML) and all the algorithms is available at github.com/uml-robotics/robot-explanation-BTs.","behavior trees, state summarization, robot explanation generation, Behavior explanation, robot transparency","",""
"Conference Paper","Wang N,Pynadath DV,Hill SG","The Impact of POMDP-Generated Explanations on Trust and Performance in Human-Robot Teams","","2016","","","997–1005","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems","Singapore, Singapore","2016","9781450342391","","","","Researchers have observed that people will more accurately trust an autonomous system, such as a robot, if they have a more accurate understanding of its decision-making process. Studies have shown that hand-crafted explanations can help maintain effective team performance even when the system is less than 100% reliable. However, current explanation algorithms are not sufficient for making a robot's quantitative reasoning (in terms of both uncertainty and conflicting goals) transparent to human teammates. In this work, we develop a novel mechanism for robots to automatically generate explanations of reasoning based on Partially Observable Markov Decision Problems (POMDPs). Within this mechanism, we implement alternate natural-language templates and then measure their differential impact on trust and team performance within an agent-based online test-bed that simulates a human-robot team task. The results demonstrate that the added explanation capability leads to improvement in transparency, trust, and team performance. Furthermore, by observing the different outcomes due to variations in the robot's explanation content, we gain valuable insight that can help lead to refinement of explanation algorithms to further improve human-robot interaction.","trust, pomdps, human-robot interaction, explainable ai","","AAMAS '16"
"Journal Article","Han Z,Yanco H","Communicating Missing Causal Information to Explain a Robot’s Past Behavior","J.  Hum. -Robot Interact.","2023","12","1","","Association for Computing Machinery","New York, NY, USA","","","2023-02","","","https://doi.org/10.1145/3568024;http://dx.doi.org/10.1145/3568024","10.1145/3568024","Robots need to explain their behavior to gain trust. Existing research has focused on explaining a robot’s current behavior, yet it remains unknown yet challenging how to provide explanations of past actions in an environment that might change after a robot’s actions, leading to critical missing causal information due to moved objects.We conducted an experiment (N = 665) investigating how a robot could help participants infer the missing causal information by replaying the past behavior physically, using verbal explanations, and projecting visual information onto the environment. Participants watched videos of the robot replaying its completion of an integrated mobile kitting task. During the replay, the objects are already gone, so participants needed to infer where an object was picked, where a ground obstacle had been, and where the object was placed.Based on the results, we recommend combining physical replay with speech and projection indicators (Replay-Project-Say) to help infer all the missing causal information (picking, navigation, and placement) from the robot’s past actions. This condition had the best outcome in both task-based—effectiveness, efficiency, and confidence—and team-based metrics—workload and trust. If one’s focus is efficiency, then we recommend projection markers for navigation inferences and verbal markers for placing inferences.","system transparency, Robot explanation, behavior explanation","",""
"Conference Paper","Cassady JT,Robinson C,Popa DO","Increasing User Trust in a Fetching Robot Using Explainable AI in a Traded Control Paradigm","","2020","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 13th ACM International Conference on PErvasive Technologies Related to Assistive Environments","Corfu, Greece","2020","9781450377737","","https://doi.org/10.1145/3389189.3393740;http://dx.doi.org/10.1145/3389189.3393740","10.1145/3389189.3393740","Recently, there has been an increase use of collaborative robots in manufacturing, healthcare, military, and personal use scenarios. Such robots operate under shared or traded control paradigms with their human operators or users. Therefore, it is important to understand how to address and improve issues of trust between the humans and collaborative robots. In this paper, we investigate the impact of robotic agent transparency to their subjective trust level by a human operator. Several experiments were conceived with the help of a fetching mobile robot under traded control, and data such as subjective trust level was collected during experimentation. Results indicate that trust is easier to lose than it is to gain. Furthermore, results also indicate that agent transparency's effect on operator trust is more significant in tasks of increasing complexity.","explainable autonomy, mobile manipulation","","PETRA '20"
"Conference Paper","de Graaf MM,Malle BF","People's Explanations of Robot Behavior Subtly Reveal Mental State Inferences","","2020","","","239–248","IEEE Press","Daegu, Republic of Korea","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","","2020","9781538685556","","","","It has long been assumed that when people observe robots they intuitively ascribe mind and intentionality to them, just as they do to humans. However, much of this evidence relies on experimenter-provided questions or self-reported judgments. We propose a new way of investigating people's mental state ascriptions to robots by carefully studying explanations of robot behavior. Since people's explanations of human behavior are deeply grounded in assumptions of mind and intentional agency, explanations of robot behavior can reveal whether such assumptions similarly apply to robots. We designed stimulus behaviors that were representative of a variety of robots in diverse contexts and ensured that people saw the behaviors as equally intentional, desirable, and surprising across both human and robot agents. We provided 121 participants with verbal descriptions of these behaviors and asked them to explain in their own words why the agent (human or robot) had performed them. To systematically analyze the verbal data, we used a theoretically grounded classification method to identify core explanation types. We found that people use the same conceptual toolbox of behavior explanations for both human and robot agents, robustly indicating inferences of intentionality and mind. But people applied specific explanatory tools at somewhat different rates and in somewhat different ways for robots, revealing specific expectations people hold when explaining robot behaviors.","human-robot-interaction, behavior explanation, folk psychology, theory of mind, mental state inference","","HRI '19"
"Conference Paper","Wich A,Schultheis H,Beetz M","Empirical Estimates on Hand Manipulation Are Recoverable: A Step Towards Individualized and Explainable Robotic Support in Everyday Activities","","2022","","","1382–1390","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems","Virtual Event, New Zealand","2022","9781450392136","","","","A key challenge for robotic systems is to figure out the behavior of another agent. The capability to draw correct inferences is crucial to derive human behavior from examples.Processing correct inferences is especially challenging when (confounding) factors are not controlled experimentally (observational evidence). For this reason, robots that rely on inferences that are correlational risk a biased interpretation of the evidence.We propose equipping robots with the necessary tools to conduct observational studies on people. Specifically, we propose and explore the feasibility of structural causal models with non-parametric estimators to derive empirical estimates on hand behavior in the context of object manipulation in a virtual kitchen scenario. In particular, we focus on inferences under (the weaker) conditions of partial confounding (the model covering only some factors) and confront estimators with hundreds of samples instead of the typical order of thousands. Studying these conditions explores the boundaries of the approach and its viability.Despite the challenging conditions, the estimates inferred from the validation data are correct. Moreover, these estimates are stable against three refutation strategies where four estimators are in agreement. Furthermore, the causal quantity for two individuals reveals the sensibility of the approach to detect positive and negative effects.The validity, stability, and explainability of the approach are encouraging and serve as the foundation for further research.","robotics, causal inference, treatment effect estimation, human behavior","","AAMAS '22"
"Conference Paper","Stange S,Kopp S","Effects of a Social Robot's Self-Explanations on How Humans Understand and Evaluate Its Behavior","","2020","","","619–627","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction","Cambridge, United Kingdom","2020","9781450367462","","https://doi.org/10.1145/3319502.3374802;http://dx.doi.org/10.1145/3319502.3374802","10.1145/3319502.3374802","Social robots interacting with users in real-life environments will often show surprising or even undesirable behavior. In this paper we investigate whether a robot's ability to self-explain its behavior affects the users' perception and assessment of this behavior. We propose an explanation model based on humans' folk-psychological concepts and test different explanation strategies in specifically designed HRI scenarios with robot behaviors perceived as intentional, but differently surprising or desirable. All types of explanation strategies increased the understandability and desirability of the behaviors. While merely stating an action had similar effects as giving a reason for it (an intention or need), combining both in a causal explanation helped the robot to better justify its behavior and to increase its understandability and desirability to a larger extent.","behavior explanations, perception study, human-robot interaction","","HRI '20"
"Conference Paper","Sridharan M,Meadows B,Colaco Z","A Tale of Many Explanations: Towards an Explanation Generation System for Robots","","2016","","","260–267","Association for Computing Machinery","New York, NY, USA","Proceedings of the 31st Annual ACM Symposium on Applied Computing","Pisa, Italy","2016","9781450337397","","https://doi.org/10.1145/2851613.2851705;http://dx.doi.org/10.1145/2851613.2851705","10.1145/2851613.2851705","A fundamental challenge in robotics is to reason with incomplete domain knowledge to explain unexpected observations, and partial descriptions of domain objects and events extracted from sensor observations. Existing explanation generation systems are based on ideas drawn from two broad classes of systems, and do not support all the desired explanation generation capabilities for robots. The objective of this paper is to first compare the explanation generation capabilities of a state of the art system from each of these two classes, using execution scenarios of a robot waiter assisting in a restaurant. Specifically, we investigate KRASP, a system based on the declarative language Answer Set Prolog, which uses an elaborate system description and observations of system behavior to explain unexpected observations and partial descriptions. We also explore UMBRA, an architecture that provides explanations using a weaker system description, a heuristic representation of past experience, and other heuristics for selectively and incrementally searching through relevant ground literals. Based on this study, this paper identifies some key criteria, and provides some recommendations, for developing an explanation generation system for robots that exploits the complementary strengths of the two classes of explanation generation systems.","heuristic guidance, robotics, explanation generation, answer set prolog, cognitive systems","","SAC '16"
"Conference Paper","Hald K,Weitz K,André E,Rehm M","“An Error Occurred!” - Trust Repair With Virtual Robot Using Levels of Mistake Explanation","","2021","","","218–226","Association for Computing Machinery","New York, NY, USA","Proceedings of the 9th International Conference on Human-Agent Interaction","Virtual Event, Japan","2021","9781450386203","","https://doi.org/10.1145/3472307.3484170;http://dx.doi.org/10.1145/3472307.3484170","10.1145/3472307.3484170","Human-robot collaboration in industrial settings is an expanding research field in robotics. When working together, robot mistakes are an important factor to decrease trust and therefore interferes with cooperation. It is unclear whether explanations help to restore human-robot trust after a mistake. In our study, we investigate whether system explanations as a trust-repairing action after a robot makes a mistake in a collaborative task is helpful. Our pilot study revealed that users are more interested in solutions to errors than they are in just why the error happened. Therefore, in our main study, we evaluated three levels of mistake explanations (no explanation, explanation, and explanation with solution) after a robot in VR made a mistake in executing a shared objective. After testing with 30 participants we found that the robot making a mistake significantly affects trust toward the robot, compared to it completing the task successfully. While participants found the explanations helpful to trust or distrust the robot, the levels of the explanation did not lead to an increase in trust towards the robot after a mistake. In addition, we found no significant impact of explanations on self-efficacy and the emotional state of the participants. Our results show that explanations alone are not sufficient to increase human-computer trust after robot mistakes.","virtual reality, human-robot trust, human-robot collaboration, XAI, robot mistakes, proximity","","HAI '21"
"Conference Paper","Wang N,Pynadath DV,Hill SG","Trust Calibration within a Human-Robot Team: Comparing Automatically Generated Explanations","","2016","","","109–116","IEEE Press","Christchurch, New Zealand","The Eleventh ACM/IEEE International Conference on Human Robot Interaction","","2016","9781467383707","","","","Trust is a critical factor for achieving the full potential of human-robot teams. Researchers have theorized that people will more accurately trust an autonomous system, such as a robot, if they have a more accurate understanding of its decision-making process. Studies have shown that hand-crafted explanations can help maintain trust when the system is less than 100% reliable. In this work, we leverage existing agent algorithms to provide a domain-independent mechanism for robots to automatically generate such explanations. To measure the explanation mechanism's impact on trust, we collected self-reported survey data and behavioral data in an agent-based online testbed that simulates a human-robot team task. The results demonstrate that the added explanation capability led to improvement in transparency, trust, and team performance. Furthermore, by observing the different outcomes due to variations in the robot's explanation content, we gain valuable insight that can help lead to refinement of explanation algorithms to further improve human-robot trust calibration.","pomdp, explainable a.i., trust, human-robot interaction","","HRI '16"
"Conference Paper","Park J,Kim J,Kim Y,Kim J,Kim MG,Choi J,Lee W","User Perception on Personalized Explanation by Science Museum Docent Robot","","2022","","","973–975","IEEE Press","Sapporo, Hokkaido, Japan","Proceedings of the 2022 ACM/IEEE International Conference on Human-Robot Interaction","","2022","","","","","As the number of docent robots in museums has increased, robot personalization services have become important. A survey-based experiment was conducted to catch the difference in perceptions of personalized service for exhibition visitors. As a result, it was found that the background knowledge of the visitors listening to the explanation had an effect on the perception of the personalized service. The finding gives us a set of design criteria for personalized museum guide robot services.","background knowledge, guidance, personalization services, docent robots, hri","","HRI '22"
"Journal Article","Schodde T,Hoffmann L,Stange S,Kopp S","Adapt, Explain, Engage—A Study on How Social Robots Can Scaffold Second-Language Learning of Children","J.  Hum. -Robot Interact.","2019","9","1","","Association for Computing Machinery","New York, NY, USA","","","2019-12","","","https://doi.org/10.1145/3366422;http://dx.doi.org/10.1145/3366422","10.1145/3366422","Social robots are increasingly applied to support children’s learning, but how a robot can foster (or may hinder) learning is still not fully clear. One technique used by teachers is scaffolding, temporarily assisting learners to achieve new skills or levels of understanding they would not reach on their own. We ask if and how a social robot can be utilized to scaffold second-language learning of children at kindergarten age (4--7 years). Specifically, we explore an adapt-and-explain scaffolding strategy in which a robot acts as a peer-like tutor who dynamically adapts its behavior or the learning tasks to the cognitive and affective state of the child, and provides verbal explanations of these adaptations. An evaluation study with 40 children shows that children benefit from the learning adaptation and that the explanations have a positive effect especially for slower learners. Further, in 76% of all cases the robot managed to “re-engage” children who started to disengage from the learning interaction, helping them to achieve an overall higher learning gain. These findings demonstrate that a social robot equipped with suitable scaffolding mechanisms can increase engagement and learning, especially when being adaptive to the individual behavior and states of a child learner.","open learner model, engagement, scaffolding, transparency, Adaptive robot tutoring","",""
"Conference Paper","Hayes B,Shah JA","Improving Robot Controller Transparency Through Autonomous Policy Explanation","","2017","","","303–312","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction","Vienna, Austria","2017","9781450343367","","https://doi.org/10.1145/2909824.3020233;http://dx.doi.org/10.1145/2909824.3020233","10.1145/2909824.3020233","Shared expectations and mutual understanding are critical facets of teamwork. Achieving these in human-robot collaborative contexts can be especially challenging, as humans and robots are unlikely to share a common language to convey intentions, plans, or justifications. Even in cases where human co-workers can inspect a robot's control code, and particularly when statistical methods are used to encode control policies, there is no guarantee that meaningful insights into a robot's behavior can be derived or that a human will be able to efficiently isolate the behaviors relevant to the interaction. We present a series of algorithms and an accompanying system that enables robots to autonomously synthesize policy descriptions and respond to both general and targeted queries by human collaborators. We demonstrate applicability to a variety of robot controller types including those that utilize conditional logic, tabular reinforcement learning, and deep reinforcement learning, synthesizing informative policy descriptions for collaborators and facilitating fault diagnosis by non-experts.","interpretable machine learning, human-robot teaming, human-robot interaction, human-robot collaboration","","HRI '17"
"Journal Article","Arnold T,Kasenberg D,Scheutz M","Explaining in Time: Meeting Interactive Standards of Explanation for Robotic Systems","J.  Hum. -Robot Interact.","2021","10","3","","Association for Computing Machinery","New York, NY, USA","","","2021-07","","","https://doi.org/10.1145/3457183;http://dx.doi.org/10.1145/3457183","10.1145/3457183","Explainability has emerged as a critical AI research objective, but the breadth of proposed methods and application domains suggest that criteria for explanation vary greatly. In particular, what counts as a good explanation, and what kinds of explanation are computationally feasible, has become trickier in light of oqaque “black box” systems such as deep neural networks. Explanation in such cases has drifted from what many philosophers stipulated as having to involve deductive and causal principles to mere “interpretation,” which approximates what happened in the target system to varying degrees. However, such post hoc constructed rationalizations are highly problematic for social robots that operate interactively in spaces shared with humans. For in such social contexts, explanations of behavior, and, in particular, justifications for violations of expected behavior, should make reference to socially accepted principles and norms. In this article, we show how a social robot’s actions can face explanatory demands for how it came to act on its decision, what goals, tasks, or purposes its design had those actions pursue and what norms or social constraints the system recognizes in the course of its action. As a result, we argue that explanations for social robots will need to be accurate representations of the system’s operation along causal, purposive, and justificatory lines. These explanations will need to generate appropriate references to principles and norms—explanations based on mere “interpretability” will ultimately fail to connect the robot’s behaviors to its appropriate determinants. We then lay out the foundations for a cognitive robotic architecture for HRI, together with particular component algorithms, for generating explanations and engaging in justificatory dialogues with human interactants. Such explanations track the robot’s actual decision-making and behavior, which themselves are determined by normative principles the robot can describe and use for justifications.","Explainability, normative HRI, architectural requirements","",""
"Conference Paper","Abdulrahman A,Richards D","Modelling Therapeutic Alliance Using a User-Aware Explainable Embodied Conversational Agent to Promote Treatment Adherence","","2019","","","248–251","Association for Computing Machinery","New York, NY, USA","Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents","Paris, France","2019","9781450366724","","https://doi.org/10.1145/3308532.3329413;http://dx.doi.org/10.1145/3308532.3329413","10.1145/3308532.3329413","Non-adherence to a treatment plan recommended by the therapist is a key cause of the increasing rate of chronic medical conditions globally. The therapist-patient therapeutic alliance is regarded as a successful intervention and a good predictor of treatment adherence. Similar to the human scenario, embodied conversational agents (ECAs) showed evidence of their ability to build an agent-patient therapeutic alliance, which motivates the effort to advance ECAs as a potential solution to improve treatment adherence and consequently the health outcome. Building therapeutic alliance implies the need for a positive environment where the ECA and the patient can share their knowledge and discuss their goals, preferences and tasks towards building a shared plan, which is commonly done using explanations. However, explainable agents commonly rely on their own knowledge and goals in providing explanations, rather than the beliefs, plans or goals of the user. It is not clear whether such explanations, in individual-specific contexts such as personal health assistance, are perceived by the user as relevant in decision-making towards their own behavior change. Therefore, in this research, we are developing a user-aware explainable ECA by embedding the cognitive agent architecture with a user model, explanation engine and modified planner to implement the concept of SharedPlans. The developed agent will be deployed and evaluated with real patients and the therapeutic alliance will be measured using standard measurements.","therapeutic alliance, explainable agent, shared planning","","IVA '19"
"Journal Article","Thellman S,Ziemke T","The Perceptual Belief Problem: Why Explainability Is a Tough Challenge in Social Robotics","J.  Hum. -Robot Interact.","2021","10","3","","Association for Computing Machinery","New York, NY, USA","","","2021-07","","","https://doi.org/10.1145/3461781;http://dx.doi.org/10.1145/3461781","10.1145/3461781","The explainability of robotic systems depends on people’s ability to reliably attribute perceptual beliefs to robots, i.e., what robots know (or believe) about objects and events in the world based on their perception. However, the perceptual systems of robots are not necessarily well understood by the majority of people interacting with them. In this article, we explain why this is a significant, difficult, and unique problem in social robotics. The inability to judge what a robot knows (and does not know) about the physical environment it shares with people gives rise to a host of communicative and interactive issues, including difficulties to communicate about objects or adapt to events in the environment. The challenge faced by social robotics researchers or designers who want to facilitate appropriate attributions of perceptual beliefs to robots is to shape human–robot interactions so that people understand what robots know about objects and events in the environment. To meet this challenge, we argue, it is necessary to advance our knowledge of when and why people form incorrect or inadequate mental models of robots’ perceptual and cognitive mechanisms. We outline a general approach to studying this empirically and discuss potential solutions to the problem.","understandability, explainability, predictability, intentional stance, belief attribution, intentionality, social robotics, common ground, mental state attribution, Human-robot interaction","",""
"Journal Article","Wijnen FM,Davison DP,Reidsma D,Meij J,Charisi V,Evers V","Now We’Re Talking: Learning by Explaining Your Reasoning to a Social Robot","J.  Hum. -Robot Interact.","2019","9","1","","Association for Computing Machinery","New York, NY, USA","","","2019-12","","","https://doi.org/10.1145/3345508;http://dx.doi.org/10.1145/3345508","10.1145/3345508","This article presents a study in which we explored the effect of a social robot on the explanatory behavior of children (aged 6--10) while working on an inquiry learning task. In a comparative experiment, we offered children either a baseline Computer Aided Learning (CAL) system or the same CAL system that was supplemented with a social robot to verbally explain their thoughts to. Results indicate that when children made observations in an inquiry learning context, the robot was better able to trigger elaborate explanatory behavior. First, this is shown by a longer duration of explanatory utterances by children who worked with the robot compared to the baseline CAL system. Second, a content analysis of the explanations indicated that children who worked with the robot included more relevant utterances about the task in their explanation. Third, the content analysis shows that children made more logical associations between relevant facets in their explanations when they explained to a robot compared to a baseline CAL system. These results show that social robots that are used as extensions to CAL systems may be beneficial for triggering explanatory behavior in children, which is associated with deeper learning.","learning by explaining, Social robotics, inquiry learning, computer-aided learning system","",""
"Conference Paper","Brandao M,Mansouri M,Mohammed A,Luff P,Coles A","Explainability in Multi-Agent Path/Motion Planning: User-Study-Driven Taxonomy and Requirements","","2022","","","172–180","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems","Virtual Event, New Zealand","2022","9781450392136","","","","Multi-Agent Path Finding (MAPF) and Multi-Robot Motion Planning (MRMP) are complex problems to solve, analyze and build algorithms for. Automatically-generated explanations of algorithm output, by improving human understanding of the underlying problems and algorithms, could thus lead to better user experience, developer knowledge, and MAPF/MRMP algorithm designs. Explanations are contextual, however, and thus developers need a good understanding of the questions that can be asked about algorithm output, the kinds of explanations that exist, and the potential users and uses of explanations in MAPF/MRMP applications. In this paper we provide a first step towards establishing a taxonomy of explanations, and a list of requirements for the development of explainable MAPF/MRMP planners. We use interviews and a questionnaire with expert developers and industry practitioners to identify the kinds of questions, explanations, users, uses, and requirements of explanations that should be considered in the design of such explainable planners. Our insights cover a diverse set of applications: warehouse automation, computer games, and mining.","explainable planning, explainable AI, multi-agent path finding, multi-robot motion planning","","AAMAS '22"
"Conference Paper","Sklar EI,Azhar MQ","Explanation through Argumentation","","2018","","","277–285","Association for Computing Machinery","New York, NY, USA","Proceedings of the 6th International Conference on Human-Agent Interaction","Southampton, United Kingdom","2018","9781450359535","","https://doi.org/10.1145/3284432.3284470;http://dx.doi.org/10.1145/3284432.3284470","10.1145/3284432.3284470","Computational Argumentation is a logical model of reasoning that has its origins in philosophy and provides a means for organising evidence for (or against) particular claims (or decisions). Argumentation-based Dialogue is a related methodology that is used for structuring interactions between two (or more) agents and has been explored within the Multi-Agent Systems community as an extended form of negotiation where agents can not only exchange claims, but also their reasons for believing (or disbelieving) those claims. Recently, the Artificial Intelligence (AI) community has become intrigued by the notion of ""Explainable AI"", in which intelligent systems are able to explain predictions or decisions to (human) users. There is a natural pairing between Explainable AI and Argumentation: the first requires the need to clarify and defend decisions and the second provides a method for linking any decision to the evidence supporting it. In this paper, we describe how the two are connected and illustrate the utility of argumentation-based dialogue as a technique for implementing Explainable AI in a human-robot system.","explainable ai, computational argumentation, human-robot interaction","","HAI '18"
"Conference Paper","Tabrez A,Agrawal S,Hayes B","Explanation-Based Reward Coaching to Improve Human Performance via Reinforcement Learning","","2020","","","249–257","IEEE Press","Daegu, Republic of Korea","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","","2020","9781538685556","","","","For robots to effectively collaborate with humans, it is critical to establish a shared mental model amongst teammates. In the case of incongruous models, catastrophic failures may occur unless mitigating steps are taken. To identify and remedy these potential issues, we propose a novel mechanism for enabling an autonomous system to detect model disparity between itself and a human collaborator, infer the source of the disagreement within the model, evaluate potential consequences of this error, and finally, provide human-interpretable feedback to encourage model correction. This process effectively enables a robot to provide a human with a policy update based on perceived model disparity, reducing the likelihood of costly or dangerous failures during joint task execution. This paper makes two contributions at the intersection of explainable AI (xAI) and human-robot collaboration: 1) The Reward Augmentation and Repair through Explanation (RARE) framework for estimating task understanding and 2) A human subjects study illustrating the effectiveness of reward augmentation-based policy repair in a complex collaborative task.","reward estimation, explainable AI, joint task execution, human-robot collaboration, policy explanation","","HRI '19"
"Conference Paper","Beaton B","Crucial Answers about Humanoid Capital","","2018","","","5–12","Association for Computing Machinery","New York, NY, USA","Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","Chicago, IL, USA","2018","9781450356152","","https://doi.org/10.1145/3173386.3173391;http://dx.doi.org/10.1145/3173386.3173391","10.1145/3173386.3173391","Inside AI research and engineering communities, explainable artificial intelligence (XAI) is one of the most provocative and promising lines of AI research and development today. XAI has the potential to make expressible the context and domain-specific benefits of particular AI applications to a diverse and inclusive array of stakeholders and audiences. In addition, XAI has the potential to make AI benefit claims more deeply evidenced. Outside AI research and engineering communities, one of the most provocative and promising lines of research happening today is the work on ""humanoid capital"" at the edges of the social, behavioral, and economic sciences. Humanoid capital theorists renovate older discussions of ""human capital"" as part of trying to make calculable and provable the domain-specific capital value, value-adding potential, or relative worth (i.e., advantages and benefits) of different humanoid models over time. Bringing these two exciting streams of research into direct conversation for the first time is the larger goal of this landmark paper. The primary research contribution of the paper is to detail some of the key requirements for making humanoid robots explainable in capital terms using XAI approaches. In this regard, the paper not only brings two streams of provocative research into much-needed conversation but also advances both streams.","humanoid robots, capital, xai, explainable artificial intelligence","","HRI '18"
"Conference Paper","Chakraborti T,Sreedharan S,Grover S,Kambhampati S","Plan Explanations as Model Reconciliation: An Empirical Study","","2020","","","258–266","IEEE Press","Daegu, Republic of Korea","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","","2020","9781538685556","","","","Recent work in explanation generation for decision making agents has looked at how unexplained behavior of autonomous systems can be understood in terms of differences in the model of the system and the human's understanding of the same, and how the explanation process as a result of this mismatch can be then seen as a process of reconciliation of these models. Existing algorithms in such settings, while having been built on contrastive, selective and social properties of explanations as studied extensively in the psychology literature, have not, to the best of our knowledge, been evaluated in settings with actual humans in the loop. As such, the applicability of such explanations to human-AI and human-robot interactions remains suspect. In this paper, we set out to evaluate these explanation generation algorithms in a series of studies in a mock search and rescue scenario with an internal semi-autonomous robot and an external human commander. During that process, we hope to demonstrate to what extent the properties of these algorithms hold as they are evaluated by humans.","explainable AI, human-robot interaction, explanations as model reconciliation, planning and decision-making","","HRI '19"
"Journal Article","Rosenthal S,Vichivanives P,Carter E","The Impact of Route Descriptions on Human Expectations for Robot Navigation","J.  Hum. -Robot Interact.","2022","11","4","","Association for Computing Machinery","New York, NY, USA","","","2022-09","","","https://doi.org/10.1145/3526104;http://dx.doi.org/10.1145/3526104","10.1145/3526104","As robots are deployed to work in our environments, we must build appropriate expectations of their behavior so that we can trust them to perform their jobs autonomously as we attend to other tasks. Many types of explanations for robot behavior have been proposed, but they have not been fully analyzed for their impact on aligning expectations of robot paths for navigation. In this work, we evaluate several types of robot navigation explanations to understand their impact on the ability of humans to anticipate a robot’s paths. We performed an experiment in which we gave participants an explanation of a robot path and then measured (i) their ability to predict that path, (ii) their allocation of attention on the robot navigating the path versus their own dot-tracking task, and (iii) their subjective ratings of the robot’s predictability and trustworthiness. Our results show that explanations do significantly affect people’s ability to predict robot paths and that explanations that are concise and do not require readers to perform mental transformations are most effective at reducing attention to the robot.","predictability, dual-task experiment, Explanations, user expectations, robot behavior, robot navigation","",""
"Conference Paper","Fukuchi Y,Osawa M,Yamakawa H,Imai M","Autonomous Self-Explanation of Behavior for Interactive Reinforcement Learning Agents","","2017","","","97–101","Association for Computing Machinery","New York, NY, USA","Proceedings of the 5th International Conference on Human Agent Interaction","Bielefeld, Germany","2017","9781450351133","","https://doi.org/10.1145/3125739.3125746;http://dx.doi.org/10.1145/3125739.3125746","10.1145/3125739.3125746","In cooperation, the workers must know how co-workers behave. However, an agent's policy, which is embedded in a statistical machine learning model, is hard to understand, and requires much time and knowledge to comprehend. Therefore, it is difficult for people to predict the behavior of machine learning robots, which makes Human Robot Cooperation challenging. In this paper, we propose Instruction-based Behavior Explanation (IBE), a method to explain an autonomous agent's future behavior. In IBE, an agent can autonomously acquire the expressions to explain its own behavior by reusing the instructions given by a human expert to accelerate the learning of the agent's policy. IBE also enables a developmental agent, whose policy may change during the cooperation, to explain its own behavior with sufficient time granularity.","human robot cooperation, instruction-based behavior explanation, interactive reinforcement learning","","HAI '17"
"Conference Paper","Abdulrahman A,Richards D,Bilgin AA","Reason Explanation for Encouraging Behaviour Change Intention","","2021","","","68–77","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems","Virtual Event, United Kingdom","2021","9781450383073","","","","The demand for intelligent virtual advisors in our rapidly advancing world is rising and, consequently, the need for understanding the reasoning process to answer why a particular piece of advice is provided to the user is directly increasing. Personalized explanation is regarded as a reliable way to improve the user's understanding and trust in the virtual advisor. So far, cognitive explainable agents utilize reason explanation by referring to their own mental state (beliefs and goals) to explain their own behaviour. However, when the explainable agent plays the role of a virtual advisor and recommends a behaviour for the human to perform, it is best to refer to the user's mental state, rather than the agent's mental state, to form a reason explanation. In this paper, we are developing an explainable virtual advisor (XVA) that communicates with the user to elicit the user's beliefs and goals and then tailors its advice and explains it according to the user's mental state. We tested the proposed XVA with university students where the XVA provides tips to reduce the students' study stress. We measured the impact of receiving three different patterns of tailored explanations (belief-based, goal-based, and belief&goal-based explanation) in terms of the students' intentions to change their behaviours. The results showed that the intention to change is not only related to the explanation pattern but also to the user context, the relationship built with the agent, the type of behaviour recommended and the user's current intention to do the behaviour.","explainable agents, personal virtual advisor, working alliance, reason explanation, behaviour change intention, trust","","AAMAS '21"
"Conference Paper","Bernardini S,Jovan F,Jiang Z,Watson S,Weightman A,Moradi P,Richardson T,Sadeghian R,Sareh S","A Multi-Robot Platform for the Autonomous Operation and Maintenance of Offshore Wind Farms","","2020","","","1696–1700","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems","Auckland, New Zealand","2020","9781450375184","","","","With the increasing scale of offshore wind farm development, maintaining farms efficiently and safely becomes a necessity. The length of turbine downtime and the logistics for human technician transfer make up a significant proportion of the operation and maintenance (O&M) costs. To reduce such costs, future O&M infrastructures will increasingly rely on offshore autonomous robotic solutions that are capable of co-managing wind farms with human operators located onshore. In particular, unmanned aerial vehicles, autonomous surface vessels, and crawling robots are expected to play important roles not only to bring down costs but also to significantly reduce the health and safety risks by assisting (or replacing) human operators in performing the most hazardous tasks. This paper portrays a visionary view in which heterogeneous robotic assets, underpinned by AI agent technology, coordinate their behavior to autonomously inspect, maintain and repair offshore wind farms over long periods of time and unstable weather conditions. They cooperate with onshore human operators, who supervise the mission at a distance, via the use of shared deliberation techniques. We highlight several challenging research directions in this context and offer ambitious ideas to tackle them as well as initial solutions.","robotics, extreme environments, wind farms, autonomy, explainability, multi-agency, ai planning","","AAMAS '20"
"Conference Paper","Helenon F,Thiery S,Nyiri E,Gibaru O","Cognitive Architecture for Intuitive and Interactive Task Learning in Industrial Collaborative Robotics","","2021","","","119–124","Association for Computing Machinery","New York, NY, USA","2021 the 5th International Conference on Robotics, Control and Automation","Seoul, Republic of Korea","2021","9781450387484","","https://doi.org/10.1145/3471985.3472385;http://dx.doi.org/10.1145/3471985.3472385","10.1145/3471985.3472385","This paper introduces a cognitive architecture, implemented in python3, designed with industrial collaborative robotics specifications in mind, to engage in a mixed-initiative teacher/learner setting called interactive task learning: a human can teach the robot, with natural and multimodal communication means, how to perform a task. The architecture has been built around explainable, modular representations (relational graphs and behavior trees) to ease the upgradability of the system and AI modules to adapt to realistic and complex settings. A first prototype based on speech and gesture communication means is proposed and has been validated on an industrial system to learn an unknown task. A link to a video of this validation is attached in the article.","","","ICRCA 2021"
"Conference Paper","Tabrez A,Luebbers MB,Hayes B","Descriptive and Prescriptive Visual Guidance to Improve Shared Situational Awareness in Human-Robot Teaming","","2022","","","1256–1264","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems","Virtual Event, New Zealand","2022","9781450392136","","","","In collaborative tasks involving human and robotic teammates, live communication between agents has potential to substantially improve task efficiency and fluency. Effective communication provides essential situational awareness to adapt successfully during uncertain situations and encourage informed decision-making. In contrast, poor communication can lead to incongruous mental models resulting in mistrust and failures. In this work, we first introduce characterizations of and generative algorithms for two complementary modalities of visual guidance: prescriptive guidance (visualizing recommended actions), and descriptive guidance (visualizing state space information to aid in decision-making). Robots can communicate this guidance to human teammates via augmented reality (AR) interfaces, facilitating synchronization of notions of environmental uncertainty and offering more collaborative and interpretable recommendations. We also introduce a min-entropy multi-agent collaborative planning algorithm for uncertain environments, informing the generation of these proactive visual recommendations for more informed human decision-making. We illustrate the effectiveness of our algorithm and compare these different modalities of AR-based guidance in a human subjects study involving a collaborative, partially observable search task. Finally, we synthesize our findings into actionable insights informing the use of prescriptive and descriptive visual guidance.","augmented reality, shared mental models, reinforcement learning, explainable AI, human-robot collaboration","","AAMAS '22"
"Journal Article","Wallkötter S,Tulli S,Castellano G,Paiva A,Chetouani M","Explainable Embodied Agents Through Social Cues: A Review","J.  Hum. -Robot Interact.","2021","10","3","","Association for Computing Machinery","New York, NY, USA","","","2021-07","","","https://doi.org/10.1145/3457188;http://dx.doi.org/10.1145/3457188","10.1145/3457188","The issue of how to make embodied agents explainable has experienced a surge of interest over the past 3 years, and there are many terms that refer to this concept, such as transparency and legibility. One reason for this high variance in terminology is the unique array of social cues that embodied agents can access in contrast to that accessed by non-embodied agents. Another reason is that different authors use these terms in different ways. Hence, we review the existing literature on explainability and organize it by (1) providing an overview of existing definitions, (2) showing how explainability is implemented and how it exploits different social cues, and (3) showing how the impact of explainability is measured. Additionally, we present a list of open questions and challenges that highlight areas that require further investigation by the community. This provides the interested reader with an overview of the current state of the art.","legibility, interpretability, explainable agency, intelligibility, embodied social agents, robots, expressive behavior, explainability, Transparency, predictability, accountability","",""
"Conference Paper","Brawer J,Ghose D,Candon K,Qin M,Roncone A,Vázquez M,Scassellati B","Interactive Policy Shaping for Human-Robot Collaboration with Transparent Matrix Overlays","","2023","","","525–533","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction","Stockholm, Sweden","2023","9781450399647","","https://doi.org/10.1145/3568162.3576983;http://dx.doi.org/10.1145/3568162.3576983","10.1145/3568162.3576983","One important aspect of effective human--robot collaborations is the ability for robots to adapt quickly to the needs of humans. While techniques like deep reinforcement learning have demonstrated success as sophisticated tools for learning robot policies, the fluency of human-robot collaborations is often limited by these policies' inability to integrate changes to a user's preferences for the task. To address these shortcomings, we propose a novel approach that can modify learned policies at execution time via symbolic if-this-then-that rules corresponding to a modular and superimposable set of low-level constraints on the robot's policy. These rules, which we call Transparent Matrix Overlays, function not only as succinct and explainable descriptions of the robot's current strategy but also as an interface by which a human collaborator can easily alter a robot's policy via verbal commands. We demonstrate the efficacy of this approach on a series of proof-of-concept cooking tasks performed in simulation and on a physical robot.","interactive robot learning, reinforcement learning, human-robot collaboration, symbolic reasoning","","HRI '23"
"Conference Paper","Camilli M,Mirandola R,Scandurra P","XSA: EXplainable Self-Adaptation","","2023","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering","Rochester, MI, USA","2023","9781450394758","","https://doi.org/10.1145/3551349.3559552;http://dx.doi.org/10.1145/3551349.3559552","10.1145/3551349.3559552","Self-adaptive systems increasingly rely on machine learning techniques as black-box models to make decisions even when the target world of interest includes uncertainty and unknowns. Because of the lack of transparency, adaptation decisions, as well as their effect on the world, are hard to explain. This often hinders the ability to trace unsuccessful adaptations back to understandable root causes. In this paper, we introduce our vision of explainable self-adaptation. We demonstrate our vision by instantiating our ideas on a running example in the robotics domain and by showing an automated proof-of-concept process providing human-understandable explanations for successful and unsuccessful adaptations in critical scenarios.","explainability, machine learning, control loop, self-adaptive systems","","ASE '22"
"Conference Paper","Tabrez A","Effective Human-Machine Teaming through Communicative Autonomous Agents That Explain, Coach, and Convince","","2023","","","3008–3010","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems","London, United Kingdom","2023","9781450394321","","","","Effective communication is essential for human-robot collaboration to improve task efficiency, fluency, and safety. Good communication between teammates provides shared situational awareness, allowing them to adapt and improvise successfully during uncertain situations, and helps identify and remedy any potential misunderstandings in the case of incongruous mental models. This doctoral proposal focuses on improving human-agent communication by leveraging explainable AI techniques to empower autonomous agents to 1) communicate insights into their capabilities and limitations to a human collaborator, 2) coach and influence human teammates' behavior during joint task execution, and 3) successfully convince and mediate trust in human-robot interactions.","human-agent collaboration, reinforcement learning, shared mental models, augmented reality, explainable ai, policy explanations","","AAMAS '23"
"Journal Article","Kaptein F,Kiefer B,Cully A,Celiktutan O,Bierman B,Rijgersberg-peters R,Broekens J,Van Vught W,Van Bekkum M,Demiris Y,Neerincx MA","A Cloud-Based Robot System for Long-Term Interaction: Principles, Implementation, Lessons Learned","J.  Hum. -Robot Interact.","2021","11","1","","Association for Computing Machinery","New York, NY, USA","","","2021-10","","","https://doi.org/10.1145/3481585;http://dx.doi.org/10.1145/3481585","10.1145/3481585","Making the transition to long-term interaction with social-robot systems has been identified as one of the main challenges in human-robot interaction. This article identifies four design principles to address this challenge and applies them in a real-world implementation: cloud-based robot control, a modular design, one common knowledge base for all applications, and hybrid artificial intelligence for decision making and reasoning. The control architecture for this robot includes a common Knowledge-base (ontologies), Data-base, “Hybrid Artificial Brain” (dialogue manager, action selection and explainable AI), Activities Centre (Timeline, Quiz, Break and Sort, Memory, Tip of the Day, ( ldots ) ), Embodied Conversational Agent (ECA, i.e., robot and avatar), and Dashboards (for authoring and monitoring the interaction). Further, the ECA is integrated with an expandable set of (mobile) health applications. The resulting system is a Personal Assistant for a healthy Lifestyle (PAL), which supports diabetic children with self-management and educates them on health-related issues (48 children, aged 6–14, recruited via hospitals in the Netherlands and in Italy). It is capable of autonomous interaction “in the wild” for prolonged periods of time without the need for a “Wizard-of-Oz” (up until 6 months online). PAL is an exemplary system that provides personalised, stable and diverse, long-term human-robot interaction.","pervasive lifestyle support, conversational agents, long-term human-robot interaction, Cloud-based robots","",""
"Conference Paper","Sukkerd R,Simmons R,Garlan D","Towards Explainable Multi-Objective Probabilistic Planning","","2018","","","19–25","Association for Computing Machinery","New York, NY, USA","Proceedings of the 4th International Workshop on Software Engineering for Smart Cyber-Physical Systems","Gothenburg, Sweden","2018","9781450357289","","https://doi.org/10.1145/3196478.3196488;http://dx.doi.org/10.1145/3196478.3196488","10.1145/3196478.3196488","Use of multi-objective probabilistic planning to synthesize behavior of CPSs can play an important role in engineering systems that must self-optimize for multiple quality objectives and operate under uncertainty. However, the reasoning behind automated planning is opaque to end-users. They may not understand why a particular behavior is generated, and therefore not be able to calibrate their confidence in the systems working properly. To address this problem, we propose a method to automatically generate verbal explanation of multi-objective probabilistic planning, that explains why a particular behavior is generated on the basis of the optimization objectives. Our explanation method involves describing objective values of a generated behavior and explaining any tradeoff made to reconcile competing objectives. We contribute: (i) an explainable planning representation that facilitates explanation generation, and (ii) an algorithm for generating contrastive justification as explanation for why a generated behavior is best with respect to the planning objectives. We demonstrate our approach on a mobile robot case study.","explainable planning, probabilistic planning, multi-objective planning","","SEsCPS '18"
"Conference Paper","Sadanand R,Chittawadigi RG,Joshi RP,Saha SK","Virtual Robots Module: An Effective Visualization Tool for Robotics Toolbox","","2015","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2015 Conference on Advances In Robotics","Goa, India","2015","9781450333566","","https://doi.org/10.1145/2783449.2783475;http://dx.doi.org/10.1145/2783449.2783475","10.1145/2783449.2783475","An introductory level robotics course mainly comprises the topics like geometry, kinematics, and dynamics of serial-chain robots. The description of the robot geometry using the Denavit-Hartenberg parameters and the kinematic and dynamic analyses require advanced mathematical concepts and are computationally intensive for robots with higher degrees-of-freedom. This calls for the use of robotics learning software, which would effectively aid the instructor to explain the concepts lucidly, and help the students in analyzing the mechanics of the robot. Robotics Toolbox is one such commonly used software, which is a collection of MATLAB-based functions that support various dedicated mathematical operations required in mechanical analysis of robots. RoboAnalyzer is another attempt towards the same goal, which focuses on the learning of robotics concepts from the physics of the robot motion. In this paper the integration of the Virtual Robots Module of RoboAnalyzer with the Robotics Toolbox is presented. With multiple number of industrial robot models, the Virtual Robots Module acts as an effective visualization add-in for the analysis performed using the Robotics Toolbox. The proposed visualization add-in can be used from software like MATLAB, MS-Excel, etc. The Virtual Robots Module allows improved visualization and easy simulation of industrial robot models for robotics research and education.","robot simulation, robotics toolbox, robot visualization","","AIR '15"
"Conference Paper","Lyu Y,Liang PP,Deng Z,Salakhutdinov R,Morency LP","DIME: Fine-Grained Interpretations of Multimodal Models via Disentangled Local Explanations","","2022","","","455–467","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society","Oxford, United Kingdom","2022","9781450392471","","https://doi.org/10.1145/3514094.3534148;http://dx.doi.org/10.1145/3514094.3534148","10.1145/3514094.3534148","The ability for a human to understand an Artificial Intelligence (AI) model's decision-making process is critical in enabling stakeholders to visualize model behavior, perform model debugging, promote trust in AI models, and assist in collaborative human-AI decision-making. As a result, the research fields of interpretable and explainable AI have gained traction within AI communities as well as interdisciplinary scientists seeking to apply AI in their subject areas. In this paper, we focus on advancing the state-of-the-art in interpreting multimodal models - a class of machine learning methods that tackle core challenges in representing and capturing interactions between heterogeneous data sources such as images, text, audio, and time-series data. Multimodal models have proliferated numerous real-world applications across healthcare, robotics, multimedia, affective computing, and human-computer interaction. By performing model disentanglement into unimodal contributions (UC) and multimodal interactions (MI), our proposed approach, DIME, enables accurate and fine-grained analysis of multimodal models while maintaining generality across arbitrary modalities, model architectures, and tasks. Through a comprehensive suite of experiments on both synthetic and real-world multimodal tasks, we show that DIME generates accurate disentangled explanations, helps users of multimodal models gain a deeper understanding of model behavior, and presents a step towards debugging and improving these models for real-world deployment.","visualization, interpretability, explainability, multimodal machine learning","","AIES '22"
"Conference Paper","Angelov D,Hristov Y,Ramamoorthy S","Using Causal Analysis to Learn Specifications from Task Demonstrations","","2019","","","1341–1349","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems","Montreal QC, Canada","2019","9781450363099","","","","Learning models of user behaviour is an important problem that is broadly applicable across many application domains requiring human-robot interaction. In this work we show that it is possible to learn a generative model for distinct user behavioral types, extracted from human demonstrations, by enforcing clustering of preferred task solutions within the latent space. We use this model to differentiate between user types and to find cases with overlapping solutions. Moreover, we can alter an initially guessed solution to satisfy the preferences that constitute a particular user type by backpropagating through the learned differentiable model. An advantage of structuring generative models in this way is that it allows us to extract causal relationships between symbols that might form part of the user's specification of the task, as manifested in the demonstrations. We show that the proposed method is capable of correctly distinguishing between three user types, who differ in degrees of cautiousness in their motion, while performing the task of moving objects with a kinesthetically driven robot in a tabletop environment. Our method successfully identifies the correct type, within the specified time, in 99% [97.8 - 99.8] of the cases, which outperforms an IRL baseline. We also show that our proposed method correctly changes a default trajectory to one satisfying a particular user specification even with unseen objects. The resulting trajectory is shown to be directly implementable on a PR2 humanoid robot completing the same task.","robot learning, human-robot interaction, explainability","","AAMAS '19"
"Conference Paper","Hofmann T,Belle V","Abstracting Noisy Robot Programs","","2023","","","534–542","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems","London, United Kingdom","2023","9781450394321","","","","Abstraction is a commonly used process to represent some low-level system by a more coarse specification with the goal to omit unnecessary details while preserving important aspects. While recent work on abstraction in the situation calculus has focused on non-probabilistic domains, we describe an approach to abstraction of probabilistic and dynamic systems. Based on a variant of the situation calculus with probabilistic belief, we define a notion of bisimulation that allows to abstract a detailed probabilistic basic action theory with noisy actuators and sensors by a possibly non-stochastic basic action theory. By doing so, we obtain abstract Golog programs that omit unnecessary details and which can be translated back to a detailed program for actual execution. This simplifies the implementation of noisy robot programs, opens up the possibility of using non-stochastic reasoning methods (e.g., planning) on probabilistic problems, and provides domain descriptions that are more easily understandable and explainable.","abstraction, robot programs, noise, logic","","AAMAS '23"
"Conference Paper","Rebanal J,Combitsis J,Tang Y,Chen Xanthony","XAlgo: A Design Probe of Explaining Algorithms’ Internal States via Question-Answering","","2021","","","329–339","Association for Computing Machinery","New York, NY, USA","26th International Conference on Intelligent User Interfaces","College Station, TX, USA","2021","9781450380171","","https://doi.org/10.1145/3397481.3450676;http://dx.doi.org/10.1145/3397481.3450676","10.1145/3397481.3450676","Algorithms often appear as ’black boxes’ to non-expert users. While prior work focuses on explainable representations and expert-oriented exploration, we propose and study an interactive approach using question answering to explain deterministic algorithms to non-expert users who need to understand the algorithms’ internal states (students learning algorithms, operators monitoring robots, admins troubleshooting network routing). We construct XAlgo—a formal model that first classifies the type of question based on a taxonomy and generates an answer based on a set of rules that extract information from representations of an algorithm’s internal states, the pseudocode. A design probe based on an algorithm learning scenario with 18 participants (9 for a Wizard-of-Oz XAlgo and 9 as a control group) reports findings and design implications based on what kinds of questions people ask, how well XAlgo responds, and what remain as challenges to bridge users’ gulf of algorithm understanding.","Algorithm, Question Answering, Explainable AI, Design Probe","","IUI '21"
"Conference Paper","Cho KJ","Motion of Soft Robots with Physically Embodied Intelligence","","2020","","","1","IEEE Press","Daegu, Republic of Korea","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","","2020","9781538685556","","","","Soft robotics deals with interaction with environments that are uncertain and vulnerable to change, by easily adapting to the environment with soft materials. However, softness inherently has large degrees of freedom which greatly complicates the motion generation. There has been no underlying principle for understanding the motion generated of soft robots. A big gap between rigid robots and soft robots has been that the kinematics of rigid robots can be defined using analytical methods, whereas the kinematics of soft robots were hard to be defined. Here, I suggest to use the minimum energy path to explain the kinematics of soft robots. The motion of soft robots follow the path where minimum energy that is required to create deformation. Hence, by plotting an energy map of a soft robot, we can estimate the motion of the soft robot and its reaction to external disturbances. Although it is extremely difficult to plot the energy map of a soft robot, this framework of using energy map to understand the motion of a soft robot can be a basis for unifying the method of explaining the motion generated by soft robots as well as rigid robots. A concept of physically embodied intelligence is a way to simplify the motion generate by soft robots by embodying intelligence into the design. Better performance can be achieved with a simpler actuation by using this concept. In nature, there are few example that exhibit this property. Flytrap, for example, can close its leaves quickly by using bistability of the leaves instead of just relying on the actuation. Inchworm achieves adaptive gripping with its prolegs by using the buckling effect. In this talk, I will give an overview of various soft robotic technologies, and some of the soft robots with physically embodied intelligence that are being developed at SNU Biorobotics Lab and Soft Robotics Research Center. These examples will show that the concept of physically embodied intelligence simplifies the design and enables better performance by exploiting the characteristics of the material and the minimum energy path concept can be a powerful tool to explain the motion generated by these robots.","soft robot, motion, embodied intelligence","","HRI '19"
"Conference Paper","Cao Y,Xu Z,Glenn T,Huo K,Ramani K","Ani-Bot: A Modular Robotics System Supporting Creation, Tweaking, and Usage with Mixed-Reality Interactions","","2018","","","419–428","Association for Computing Machinery","New York, NY, USA","Proceedings of the Twelfth International Conference on Tangible, Embedded, and Embodied Interaction","Stockholm, Sweden","2018","9781450355681","","https://doi.org/10.1145/3173225.3173226;http://dx.doi.org/10.1145/3173225.3173226","10.1145/3173225.3173226","Ani-Bot is a modular robotics system that allows users to control their DIY robots using Mixed-Reality Interaction (MRI). This system takes advantage of MRI to enable users to visually program the robot through the augmented view of a Head-Mounted Display (HMD). In this paper, we first explain the design of the Mixed-Reality (MR) ready modular robotics system, which allows users to instantly perform MRI once they finish assembling the robot. Then, we elaborate the augmentations provided by the MR system in the three primary phases of a construction kit's lifecycle: Creation, Tweaking, and Usage. Finally, we demonstrate Ani-Bot with four application examples and evaluate the system with a two-session user study. The results of our evaluation indicate that Ani-Bot does successfully embed MRI into the lifecycle (Creation, Tweaking, Usage) of DIY robotics and that it does show strong potential for delivering an enhanced user experience.","human-robot interaction, user interface, diy robotics, modular robotics, mixed-reality","","TEI '18"
"Conference Paper","Milliez G,Lallement R,Fiore M,Alami R","Using Human Knowledge Awareness to Adapt Collaborative Plan Generation, Explanation and Monitoring","","2016","","","43–50","IEEE Press","Christchurch, New Zealand","The Eleventh ACM/IEEE International Conference on Human Robot Interaction","","2016","9781467383707","","","","One application of robotics is to assist humans in the achievement of tasks they face in both the workplace and domestic environments. In some situations, a task may require the robot and the human to act together in a collaborative way in order to reach a common goal. To achieve a collaborative plan, each agent (human, robot) needs to be aware of the tasks she/he must carry out and how to perform them. This paper addresses the issue of enhancing a robotic system with a dynamic model of its collaborator's knowledge concerning tasks of a shared plan. Using this model, the robot is able to adapt its collaborative plan generation, its abilities to give explanations and to monitor the overall plan execution.We present the algorithm we have elaborated to take advantage of the tree representation of our Hierarchical Task Network (HTN) planner to enhance the robot with appropriate explanation and execution monitoring abilities.To evaluate how our adaptive system is perceived by users and how much it improves the quality of the Human-Robot interaction, the outcome of a comparative study is presented.","human knowledge awareness, shared plan, joint action, htn, hri","","HRI '16"
"Journal Article","Eggert DW,Martinez C","Using the NAO Humanoid Robot in the Classroom","J. Comput. Sci. Coll.","2014","29","6","9–11","Consortium for Computing Sciences in Colleges","Evansville, IN, USA","","","2014-06","","1937-4771","","","Robotics is a growing area, as evidenced by DARPA's recent Grand Challenge. A currently popular humanoid robot, NAO, developed by Aldebaran Robotics, has been used in many classroom activities, as well as competitions such as Robocup. This workshop will describe the features of NAO and introduce its software development environment, which includes a graphical programming language, a simulator, and APIs for many languages. Example programs developed in the graphical environment, as well as using the Python API, will be demonstrated and explained. A hands-on activity will allow participants to use either programming environment to perform a simple task. Ideas for using NAO in various settings will be presented as well. This workshop is intended for instructors at many levels. A Windows/Mac laptop is recommended.","","",""
"Conference Paper","Hendrich N,Bistry H,Adler B,Zhang J","User-Driven Software Design for an Elderly Care Service Robot","","2014","","","142–149","ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)","Brussels, BEL","Proceedings of the 8th International Conference on Pervasive Computing Technologies for Healthcare","Oldenburg, Germany","2014","9781631900112","","https://doi.org/10.4108/icst.pervasivehealth.2014.254956;http://dx.doi.org/10.4108/icst.pervasivehealth.2014.254956","10.4108/icst.pervasivehealth.2014.254956","This paper describes a service- and scenario-driven software architecture for the ambient assisted living infrastructure currently under development in the Robot-Era project. Involving the end-users from the start, the project integrates an ambient sensor network with an advanced knowledge-representation and planning system and three different robots for outdoor, condominium, and indoor service roles. We explain the design decisions for the user-friendly and medium-cost service robot, with a focus on the integration of the ROS-based sensing and manipulation capabilities with precise indoor navigation and the PEIS middleware for ubiquitous robotics.","ambient sensor networks, assisted living, elderly care, service robotics","","PervasiveHealth '14"
"Conference Paper","Bobu A,Scobee DR,Fisac JF,Sastry SS,Dragan AD","LESS is More: Rethinking Probabilistic Models of Human Behavior","","2020","","","429–437","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction","Cambridge, United Kingdom","2020","9781450367462","","https://doi.org/10.1145/3319502.3374811;http://dx.doi.org/10.1145/3319502.3374811","10.1145/3319502.3374811","Robots need models of human behavior for both inferring human goals and preferences, and predicting what people will do. A common model is the Boltzmann noisily-rational decision model, which assumes people approximately optimize a reward function and choose trajectories in proportion to their exponentiated reward. While this model has been successful in a variety of robotics domains, its roots lie in econometrics, and in modeling decisions among different discrete options, each with its own utility or reward. In contrast, human trajectories lie in a continuous space, with continuous-valued features that influence the reward function. We propose that it is time to rethink the Boltzmann model, and design it from the ground up to operate over such trajectory spaces. We introduce a model that explicitly accounts for distances between trajectories, rather than only their rewards. Rather than each trajectory affecting the decision independently, similar trajectories now affect the decision together. We start by showing that our model better explains human behavior in a user study. We then analyze the implications this has for robot inference, first in toy environments where we have ground truth and find more accurate inference, and finally for a 7DOF robot arm learning from user demonstrations.","robot inference and prediction, human decision modeling","","HRI '20"
"Conference Paper","Lutz C,Tamò A","RoboCode-Ethicists: Privacy-Friendly Robots, an Ethical Responsibility of Engineers?","","2015","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the ACM Web Science Conference","Oxford, United Kingdom","2015","9781450336727","","https://doi.org/10.1145/2786451.2786465;http://dx.doi.org/10.1145/2786451.2786465","10.1145/2786451.2786465","This article asks why engineers building robots should consider privacy aspects when programming their gadgets. We start with a definition of robots, differentiating active, social robots from passive, non-social robots. We then discuss the related literature on the privacy implications of social robots. Two aspects are of fundamental concern in this context: the pervasiveness and intrusiveness of robots on the one hand and a general lack of awareness and knowledge about how robots work, collect and process sensitive data on the other hand. We explain how the existing literature on robot ethics provides a suitable framework to address these two issues. In particular, robot ethics are useful to point out how engineers' and regulators' mindset towards privacy protection differs. The paper argues that different -- at first sight incommensurable -- rationalities exist when it comes to robotic privacy. As a contribution to the emerging field of robotic privacy, we propose an interdisciplinary and collaborative approach that bridges the two rationalities. This approach considers the role of code as the central governing element of robots. RoboCode-Ethicists, trans-disciplinary experts trained in the technical/computational, legal and social aspects of robotics, should lead the way in the discussion on robotic privacy. They could mediate between different stakeholders -- mainly regulators, users and engineers -- and address emerging privacy issues as early as possible.","Robots, Privacy, Ethical Coding, Applied Ethics","","WebSci '15"
"Conference Paper","Kyrylov V","Integrating the Computer Science Curriculum by Using Robot Soccer Simulator","","2013","","","","Society for Computer Simulation International","San Diego, CA, USA","Proceedings of the Emerging M&S Applications in Industry & Academia / Modeling and Humanities Symposium","San Diego, California","2013","9781627480390","","","","Robot soccer simulator is a reasonably complex software system that appears to be suitable as an instructive case study for Computer Science and Information Technology curricula. This has been noticed by many educators. All of them were using the well-known RoboCup soccer simulator. However, previous studies that explored this opportunity were narrowly focused on courses in Robotics and AI neglecting other possibilities. To some extent, this could be explained by that the RoboCup simulator is over complicated for undergraduate students (although it is good for students in masters program). We overcome this difficulty by proposing a simplified, yet sophisticated enough, soccer simulator having some extra features. As the result, our simulator, Tao of Soccer, can be used in a wide range of CS & IT courses. This paper explores opportunities for across-curriculum integration using Tao of Soccer as a business case and the synergies that this approach can create for learners.","across-curriculum integration, RoboCup, tao of soccer, robotic soccer, simulated soccer","","EAIA and MatH '13"
"Conference Paper","Tsang E,Gavan C,Anderson M","The Practical Application of LEGO® MINDSTORMS® Robotics Kits: Does It Enhance Undergraduate Computing Students' Engagement in Learning the Java Programming Language?","","2014","","","121–126","Association for Computing Machinery","New York, NY, USA","Proceedings of the 15th Annual Conference on Information Technology Education","Atlanta, Georgia, USA","2014","9781450326865","","https://doi.org/10.1145/2656450.2656454;http://dx.doi.org/10.1145/2656450.2656454","10.1145/2656450.2656454","This research investigates the extent to which the practical application of robotics affects undergraduate computing students' engagement in learning the Java programming language. Current literature suggests that the practical application of objects enables students to engage and understand concepts within engineering, robotics and computing disciplines easier than purely theoretical teaching methods. This research measures student engagement based on affective, behavioural, cognitive and performance engagement factors. Questionnaires, interviews and observations were exercised in order to explore the reasons that student engagement is affected. The findings suggest that the LEGO® MINDSTORMS® robotics are positively engaging students to learn the Java programming language at an undergraduate level. Negative aspects, of limitations and non-participation, may be explained through external factors including the structure of the module and peer and social pressure.","human factors, design, management, theory","","SIGITE '14"
"Conference Paper","Bahuguna J,Chittawadigi RG,Saha SK","Teaching and Learning of Robot Kinematics Using RoboAnalyzer Software","","2013","","","1–6","Association for Computing Machinery","New York, NY, USA","Proceedings of Conference on Advances In Robotics","Pune, India","2013","9781450323475","","https://doi.org/10.1145/2506095.2506142;http://dx.doi.org/10.1145/2506095.2506142","10.1145/2506095.2506142","Robots are used at various places for different applications and hence the subjects related to robotics find their place in the courses of Mechanical and Electrical engineering disciplines. The concepts of robotics are typically difficult to understand from images and figures, thus several software to aid the learning of these concepts have been developed. RoboAnalyzer is one such software developed by the authors to perform kinematic and dynamic analyses of serial robots. It is an ongoing activity and in this paper, the modules of ""Visualization of DH Parameters and Transformations"", ""3D CAD Model Importer"" and ""Inverse Kinematics"" are explained and illustrated. RoboAnalyzer software can be downloaded for free from http://www.roboanalyzer.com and can be used almost instantly.","DH Parameters, Inverse Kinematics, 3D Robot Models, Robotics Learning Software","","AIR '13"
"Conference Paper","Karli UB,Cao S,Huang CM","""What If It Is Wrong"": Effects of Power Dynamics and Trust Repair Strategy on Trust and Compliance in HRI","","2023","","","271–280","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction","Stockholm, Sweden","2023","9781450399647","","https://doi.org/10.1145/3568162.3576964;http://dx.doi.org/10.1145/3568162.3576964","10.1145/3568162.3576964","Robotic systems designed to work alongside people are susceptible to technical and unexpected errors. Prior work has investigated a variety of strategies aimed at repairing people's trust in the robot after its erroneous operations. In this work, we explore the effect of post-error trust repair strategies (promise and explanation) on people's trust in the robot under varying power dynamics (supervisor and subordinate robot). Our results show that, regardless of the power dynamics, promise is more effective at repairing user trust than explanation. Moreover, people found a supervisor robot with verbal trust repair to be more trustworthy than a subordinate robot with verbal trust repair. Our results further reveal that people are prone to complying with the supervisor robot even if it is wrong. We discuss the ethical concerns in the use of supervisor robot and potential interventions to prevent improper compliance in users for more productive human-robot collaboration.","human-robot power dynamics, human-robot collaboration, human-robot trust, trust repair","","HRI '23"
"Conference Paper","De Raffaele C,Smith S,Gemikonakli O","Enabling the Effective Teaching and Learning of Advanced Robotics in Higher Education Using an Active TUI Framework","","2017","","","7–12","Association for Computing Machinery","New York, NY, USA","Proceedings of the 3rd Africa and Middle East Conference on Software Engineering","Cairo, Egypt","2017","9781450355124","","https://doi.org/10.1145/3178298.3178299;http://dx.doi.org/10.1145/3178298.3178299","10.1145/3178298.3178299","This paper presents a tangible user interface (TUI) architecture to help mitigate the educational difficulties in teaching and learning abstract and complex concepts in Software Engineering and Robotics. The tailored design and development of this innovative framework address the unique challenges faced in higher education to actively engage students in technical concepts required to develop smart knowledge infrastructures. The novel integration of active tangible components on TUI tabletop architectures is presented within this paper and evaluated for its effectiveness as an educational technology to explain Robot Operating System (ROS) based sensor network topologies. Analysis of assessed results highlight the aptness and effectiveness of the proposed TUI framework in delivering a knowledge gain of 14.6% over traditional educational technologies. This illustrates the aptness and suitability of integrating tangible technology for abstracted software and robotic engineering concepts within higher educational institutions.","Higher Education, Active Tangible User Interface, Embedded Interaction, Robot Operating System, Educational Technology","","AMECSE '17"
"Conference Paper","Otterbacher J,Talias M","S/He's Too Warm/Agentic! The Influence of Gender on Uncanny Reactions to Robots","","2017","","","214–223","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction","Vienna, Austria","2017","9781450343367","","https://doi.org/10.1145/2909824.3020220;http://dx.doi.org/10.1145/2909824.3020220","10.1145/2909824.3020220","Gender stereotypes are strong influences on human behavior. Given our tendency to anthropomorphize, incorporating gender cues into a robot's design can influence acceptance by humans. However, little is known about the interaction between human and robot gender. We focus on the role of gender in eliciting negative, ``uncanny"" reactions from observers. We create a corpus of YouTube videos featuring robots with female, male and no gender cues. Our experiment is grounded in Gray and Wegner's (2012) model, which holds that uncanny reactions are driven by the perception of robot agency (i.e., ability to plan and control) and experience (i.e., ability to feel), which in turn, is driven by robot appearance and behavior. Participants watched videos and completed questionnaires to gauge perceptions of robots as well as affective reactions. We used Structural Equation Modeling to test whether the model explains reactions of both men and women. For gender-neutral robots, it does. However, we find a salient human-robot gender interaction. Men's uncanny reactions to robots with female cues are best predicted by the perception of experience, while women's negativity toward masculine robots is driven by perceived agency. The result is interpreted in light of the ``Big Two"" dimensions of person perception, which underlie expectations for women to be warm and men to be agentic. When a robot meets these expectations, it increases the chances of an uncanny reaction in the other-gender observer.","measurement, ""big two"" dimensions, social perception, experimentation, uncanny reaction, gender stereotypes","","HRI '17"
"Conference Paper","Dhiman NK,Deodhare D,Khemani D","A ROS Based Framework for Multi-Floor Navigation for Unmanned Ground Robots","","2020","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the Advances in Robotics 2019","Chennai, India","2020","9781450366502","","https://doi.org/10.1145/3352593.3352654;http://dx.doi.org/10.1145/3352593.3352654","10.1145/3352593.3352654","This paper presents use of a cost graph as a representation of a multi-floor building to enable the multi-floor autonomous navigation capability for a team of robot(s). A method for global path planning on this cost graph have been presented. A navigation stack provides a framework for building autonomous navigation capabilities. A navigation stack which enables use of the proposed approach for navigation in a multi-floor building and enables multi-robot operations has been detailed. The improvements provided by the proposed navigation stack over the existing ROS (Robot Operating System) navigation stack have been explained. A way to integrate multiple local path-execution nodes which can combine together to execute the planned global path has also been explained. The paper also demonstrates the reuse of existing ROS compliant source codes for implementation of the proposed navigation stack, thereby optimizing the use of proven and established technology. Further, the extensions to different components of the existing ROS navigation stack, definition of new ROS messages and action definitions, to enable interaction between the components of the stack has been explained. The paper concludes with a brief study on how the proposed stack can be used for multi-robot operations.","Navigation architecture, ROS, map representation, autonomous navigation, planning","","AIR 2019"
"Conference Paper","Golchinfar D,Vaziri DD,Stevens G,Schreiber D","Let's Go to the Mall: Investigating the Role of User Experience in Customers’ Intention to Use Social Robots in a Shopping Mall","","2022","","","377–386","Association for Computing Machinery","New York, NY, USA","Designing Interactive Systems Conference","Virtual Event, Australia","2022","9781450393584","","https://doi.org/10.1145/3532106.3533490;http://dx.doi.org/10.1145/3532106.3533490","10.1145/3532106.3533490","Aim of this study is to investigate the effects of user experience (UX) on shopping mall customers’ intention to use a social robot. Therefore, we used a Wizard of Oz approach that enabled data collection in situ. Quantitative data was obtained from a questionnaire completed by shopping mall customers who interacted with a social robot. Data was used in a regression analysis, where user experience factors served as predictors for robot use in retail. The regression model explains up to 23.2% of the variance in customers’ intention to use a social robot. In addition, we collected qualitative data on human-robot-interactions and used the data to complement the interpretation of statistical results. Our findings suggest that only hedonic qualities significantly contribute to the prediction of customers’ intention, that shopping mall customers are reluctant to grant pragmatic qualities to social robots, and that UX evaluation in HRI requires additional predictors.","user study, social robots, Human-robot interaction, wizard of oz, user experience","","DIS '22"
"Conference Paper","Lee DH,Jang S,Cho HK","MOCCA Studio: A Graphical Tool for High-Level Programming of Human-Robot Social Interaction","","2020","","","620–621","IEEE Press","Daegu, Republic of Korea","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","","2020","9781538685556","","","","In this paper, we introduce a handy and affordable solution we are developing, for education of human-robot social interaction. The solution consists of a smart device-controlled robot with a 3D printed body, a cloud-based integrated development environment that provides intuitive programming and simulation of the robot, and embedded functions enabling intelligent, natural response of the robot. The outline and architecture of the proposed system are briefly explained.","robot control architecture, human-robot social interaction, graphical programming tool","","HRI '19"
"Conference Paper","Sadeghi MM,Kececi EF","Off-the-Shelf Electronics in Rescue Robotics","","2018","","","57–61","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2018 2nd International Conference on Mechatronics Systems and Control Engineering","Amsterdam, Netherlands","2018","9781450363792","","https://doi.org/10.1145/3185066.3185072;http://dx.doi.org/10.1145/3185066.3185072","10.1145/3185066.3185072","The design and manufacturing methods of rescue robots with different locomotion principles are explained in the literature in detail. However, the design and realization of electronic circuits of a rescue robot still pose a great challenge, especially for the academics with mechanical background, who know how to design and build the mechanics of the robot but do not know how to make the robot work and make the right choices for the electronic parts, such as selecting a microcontroller or drivers. This research reports the methodology of building an electronic system for a mobile robot with off-the-shelf products.","Off-the-shelf electronic, electronic system design, robot prototyping","","ICMSCE 2018"
"Conference Paper","Cagiltay B,Mutlu B,Michaelis JE","“My Unconditional Homework Buddy:” Exploring Children’s Preferences for a Homework Companion Robot","","2023","","","375–387","Association for Computing Machinery","New York, NY, USA","Proceedings of the 22nd Annual ACM Interaction Design and Children Conference","Chicago, IL, USA","2023","","","https://doi.org/10.1145/3585088.3589388;http://dx.doi.org/10.1145/3585088.3589388","10.1145/3585088.3589388","We aim to design robotic educational support systems that can promote socially and intellectually meaningful learning experiences for students while they complete school work outside of class. To pursue this goal, we conducted participatory design studies with 10 children (aged 10–12) to explore their design needs for robot-assisted homework. We investigated children’s current ways of doing homework, the type of support they receive while doing homework, and co-designed the speech and expressiveness of a homework companion robot. Children and parents attending our design sessions explained that an emotionally expressive social robot as a homework aid can support students’ motivation and engagement, as well as their affective state. Children primarily perceived the robot as a dedicated assistant at home, capable of forming meaningful friendships, or a shared classroom learning resource. We present key design recommendations to support students’ homework experiences with a learning companion robot.","family-centered design, Child-robot interaction, interaction design, learning companion robots","","IDC '23"
"Conference Paper","Bobu A,Wiggert M,Tomlin C,Dragan AD","Feature Expansive Reward Learning: Rethinking Human Input","","2021","","","216–224","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction","Boulder, CO, USA","2021","9781450382892","","https://doi.org/10.1145/3434073.3444667;http://dx.doi.org/10.1145/3434073.3444667","10.1145/3434073.3444667","When a person is not satisfied with how a robot performs a task, they can intervene to correct it. Reward learning methods enable the robot to adapt its reward function online based on such human input, but they rely on handcrafted features. When the correction cannot be explained by these features, recent work in deep Inverse Reinforcement Learning (IRL) suggests that the robot could ask for task demonstrations and recover a reward defined over the raw state space. Our insight is that rather than implicitly learning about the missing feature(s) from demonstrations, the robot should instead ask for data that explicitly teaches it about what it is missing. We introduce a new type of human input in which the person guides the robot from states where the feature being taught is highly expressed to states where it is not. We propose an algorithm for learning the feature from the raw state space and integrating it into the reward function. By focusing the human input on the missing feature, our method decreases sample complexity and improves generalization of the learned reward over the above deep IRL baseline. We show this in experiments with a physical 7DOF robot manipulator, as well as in a user study conducted in a simulated environment.","robot learning from human input, human teachers","","HRI '21"
"Conference Paper","Potts B,Taravella B,Thiel R","Proof of Concept Development and Motion Verification of a Swimming Anguilliform Robot (NEELBOT-1.0)","","2013","","","","Society for Modeling & Simulation International","Vista, CA","Proceedings of the 2013 Grand Challenges on Modeling and Simulation Conference","Toronto, Ontario, Canada","2013","9781627482752","","","","This article illustrates the development and motion verification of a swimming, anguilliform robot whose goal is to imitate the motion described by the wakeless swimming theory derived in Vorus and Taravella (2011) and to provide a proof of concept and knowledge for the next robotic design revision which will be used for experimental validation (or invalidation) of the theory. The concept design was initially open-ended with the only constraints being the length, cross section, and the theoretical shape function to be attained. Various component options were researched and decided upon for each aspect of the robot's design such as the waterproofing skin, flexible joint assembly, motion actuators, motion control, power source, wiring, and material properties of the robot's supporting structure. In parallel, a tethered testing apparatus was designed around the robot for it to be attached to a marine testing facility's tow tank carriage. While tethered to the testing mechanism, the NEELBOT-1.0's underwater swimming motion was measured with image processing software. This image processing analysis has been very successful in comparing the robot's motion to that proposed by the theory, and the mathematical method of the image processing program is explained within. The results of the analysis have quantitatively described the slight errors in the motion and what is needed to improve the results. This initial robotic design and motion measuring method have been proven to be very successful up to this stage in the project, and the current measuring method will be continued. Future design improvements for the robot for hydrodynamic testing of the wakeless swimming theory will also be discussed.","anguilliform swimming, robotics, hydrodynamics, biomimetics","","GCMS '13"
"Conference Paper","Walker N,Weatherwax K,Allchin J,Takayama L,Cakmak M","Human Perceptions of a Curious Robot That Performs Off-Task Actions","","2020","","","529–538","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction","Cambridge, United Kingdom","2020","9781450367462","","https://doi.org/10.1145/3319502.3374821;http://dx.doi.org/10.1145/3319502.3374821","10.1145/3319502.3374821","Researchers have proposed models of curiosity as a means to drive robots to learn and adapt to their environments. While these models balance goal- and exploration-oriented actions in a mathematically principled manor, it is not understood how users perceive a robot that pursues off-task actions. Motivated by a model of curiosity based on intrinsic rewards, we conducted three online video-surveys with a total of 264 participants, evaluating a variety of curious behaviors. Our results indicate that a robot's off-task actions are perceived as expressions of curiosity, but that these actions lead to a negative impact on perceptions of the robot's competence. When the robot explains or acknowledges its deviation from the primary task, this can partially mitigate the negative effects of off-task actions.","perceptions of robots, off-task actions, curiosity","","HRI '20"
"Conference Paper","Van Campenhout L,Van Camp M,Vancoppenolle W","Exploring Tangible VR as a Tool for Workplace Design","","2020","","","33–36","Association for Computing Machinery","New York, NY, USA","Companion Proceedings of the 2020 Conference on Interactive Surfaces and Spaces","Virtual Event, Portugal","2020","9781450375269","","https://doi.org/10.1145/3380867.3426202;http://dx.doi.org/10.1145/3380867.3426202","10.1145/3380867.3426202","In this paper, we present a demonstrator that combines elements of physical prototyping and Virtual Reality. Our goal is to integrate VR in the design process of workplaces, not as a replacement of physical prototyping, but complementary to it. We call this approach Tangible Virtual Reality. We discuss our own background in embodied interaction, and present the context for our research: an industrial work cell for human-robot interaction, proposed by Audi Brussels, Kuka Belgium and FRS Robotics. We explain and illustrate how we used 3D CAD geometry to create a VR model and a physical prototype, and how we mapped them over one another. The result is a demonstrator that offers a VR experience, enhanced with real tactile information, and channeled by the natural limitations of the physical world. We suggest where the benefits of this physical/virtual design approach lay, and discuss how it could be operationalized in workplace design practice.","embodied interaction, workplace design, virtual reality, human-robot interaction","","ISS '20"
"Journal Article","Nikolaidis S,Kwon M,Forlizzi J,Srinivasa S","Planning with Verbal Communication for Human-Robot Collaboration","J.  Hum. -Robot Interact.","2018","7","3","","Association for Computing Machinery","New York, NY, USA","","","2018-11","","","https://doi.org/10.1145/3203305;http://dx.doi.org/10.1145/3203305","10.1145/3203305","Human collaborators coordinate effectively their actions through both verbal and non-verbal communication. We believe that the the same should hold for human-robot teams. We propose a formalism that enables a robot to decide optimally between taking a physical action toward task completion and issuing an utterance to the human teammate. We focus on two types of utterances: verbal commands, where the robot asks the human to take a physical action, and state-conveying actions, where the robot informs the human about its internal state, which captures the information that the robot uses in its decision making. Human subject experiments show that enabling the robot to issue verbal commands is the most effective form of communicating objectives, while retaining user trust in the robot. Communicating information about the robot’s state should be done judiciously, since many participants questioned the truthfulness of the robot statements when the robot did not provide sufficient explanation about its actions.","Human-robot collaboration, planning under uncertainty, partially observable Markov decision process, verbal communication","",""
"Conference Paper","Qin M,Huang Y,Stumph E,Santos L,Scassellati B","Dog Sit! Domestic Dogs (Canis Familiaris) Follow a Robot's Sit Commands","","2020","","","16–24","Association for Computing Machinery","New York, NY, USA","Companion of the 2020 ACM/IEEE International Conference on Human-Robot Interaction","Cambridge, United Kingdom","2020","9781450370578","","https://doi.org/10.1145/3371382.3380734;http://dx.doi.org/10.1145/3371382.3380734","10.1145/3371382.3380734","As personal social robots become more prevalent, the need for the designs of these systems to explicitly consider pets become more apparent. However, it is not known whether dogs would interact with a social robot. In two experiments, we investigate whether dogs respond to a social robot after the robot called their names, and whether dogs follow the 'sit' commands given by the robot. We conducted a between-subjects study (n = 34) to compare dogs' reactions to a social robot with a loudspeaker. Results indicate that dogs gazed at the robot more often after the robot called their names than after the loudspeaker called their names. Dogs followed the 'sit' commands more often given by the robot than given by the loudspeaker. The contribution of this study is that it is the first study to provide preliminary evidence that 1) dogs showed positive behaviors to social robots and that 2) social robots could influence dog's behaviors. This study enhance the understanding of the nature of the social interactions between humans and social robots from the evolutionary approach. Possible explanations for the observed behavior might point toward dogs perceiving robots as agents, the embodiment of the robot creating pressure for socialized responses, or the multimodal (i.e., verbal and visual) cues provided by the robot being more attractive than our control condition.","social robot, animal-robot interactions, evolutionary approach, canine","","HRI '20"
"Conference Paper","Kim S,Yu Z,Kim J,Ojha A,Lee M","Human-Robot Interaction Using Intention Recognition","","2015","","","299–302","Association for Computing Machinery","New York, NY, USA","Proceedings of the 3rd International Conference on Human-Agent Interaction","Daegu, Kyungpook, Republic of Korea","2015","9781450335270","","https://doi.org/10.1145/2814940.2815002;http://dx.doi.org/10.1145/2814940.2815002","10.1145/2814940.2815002","Recognition of human intention is an important issue in human-robot interaction research and allows a robot to respond adequately according to human's wish. In this paper, we discuss how robots can infer human intention by learning affordance, a concept used to represent the relation between an agent and its environment. Learning of the robot, to understand human and its interaction with environment, is achieved within the framework of action-perception cycle. The action-perception cycle explains how an intelligent agent learns and enhances its ability continuously by interacting with its surrounding. The proposed intention recognition and recommendation system includes several key functions such as joint attention, object recognition, affordance model, motion understanding module and so on. The experimental results show high successful recognition performance and the plausibility of the proposed system.","action-perception cycle, deep learning, human robot interaction, intention recognition","","HAI '15"
"Journal Article","Mikalonytundefined ES,Kneer M","Can Artificial Intelligence Make Art?: Folk Intuitions as to Whether AI-Driven Robots Can Be Viewed as Artists and Produce Art","J.  Hum. -Robot Interact.","2022","11","4","","Association for Computing Machinery","New York, NY, USA","","","2022-09","","","https://doi.org/10.1145/3530875;http://dx.doi.org/10.1145/3530875","10.1145/3530875","In two experiments (total N = 693), we explored whether people are willing to consider paintings made by AI-driven robots as art, and robots as artists. Across the two experiments, we manipulated three factors: (i) agent type (AI-driven robot vs. human agent), (ii) behavior type (intentional creation of a painting vs. accidental creation), and (iii) object type (abstract vs. representational painting). We found that people judge robot paintings and human paintings as art to roughly the same extent. However, people are much less willing to consider robots as artists than humans, which is partially explained by the fact that they are less disposed to attribute artistic intentions to robots.","creativity, AI art, Artificial intelligence, aesthetics, mental states","",""
"Conference Paper","Yoshiuchi H,Matsuda T,Dai J","Data Analysis Technology of Service Robot System for Business Improvement","","2020","","","7–11","Association for Computing Machinery","New York, NY, USA","Proceedings of the 5th International Conference on Robotics and Artificial Intelligence","Singapore, Singapore","2020","9781450372350","","https://doi.org/10.1145/3373724.3373733;http://dx.doi.org/10.1145/3373724.3373733","10.1145/3373724.3373733","Various kinds of data can be collected with service robot in business scenes and it is important to utilize such data for business improvement. In this paper, the research results of data analysis technology for business improvement as a function of operation and management system for service robot is explained. Through evaluation experiment for service robot in business exhibition, we clarified how to modify service scenario for business improvement and potential effect of business improvement is 8.1 %.","Data analysis, Business improvement, Service robot system, Operation and management","","ICRAI '19"
"Journal Article","Fischer K","Tracking Anthropomorphizing Behavior in Human-Robot Interaction","J.  Hum. -Robot Interact.","2021","11","1","","Association for Computing Machinery","New York, NY, USA","","","2021-10","","","https://doi.org/10.1145/3442677;http://dx.doi.org/10.1145/3442677","10.1145/3442677","Existing methodologies to describe anthropomorphism in human-robot interaction often rely either on specific one-time responses to robot behavior, such as keeping the robot's secret, or on post hoc measures, such as questionnaires. Currently, there is no method to describe the dynamics of people's behavior over the course of an interaction and in response to robot behavior. In this paper, I propose a method that allows the researcher to trace anthropomorphizing and non-anthropomorphizing responses to robots dynamically moment-by-moment over the course of human-robot interactions. I illustrate this methodology in a case study and find considerable variation between participants, but also considerable intrapersonal variation in the ways the robot is anthropomorphized. That is, people may respond to the robot as if it was another human in one moment and to its machine-like properties in the next. These findings may influence explanatory models of anthropomorphism.","computers-are-social-actors, methodology, mindless transfer, Anthropomorphism, interaction analysis","",""
"Conference Paper","Bucci P,Zhang L,Cang XL,MacLean KE","Is It Happy? Behavioural and Narrative Frame Complexity Impact Perceptions of a Simple Furry Robot's Emotions","","2018","","","1–11","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","Montreal QC, Canada","2018","9781450356206","","https://doi.org/10.1145/3173574.3174083;http://dx.doi.org/10.1145/3173574.3174083","10.1145/3173574.3174083","Critical to social human-robot interaction is a robot's emotional richness, expressed within the parameters of its physical display. While emotion arousal is straightforward to convey, human valence (positivity) evaluations are famously ambiguous, whether we are assessing other humans or a robot. Imagine someone breathing raggedly: are they nervous, or excited? To assess the premise that irregular breathing connotes low valence (emotion negativity), we implemented different levels of breathing variability and complexity in simple furry robots. We asked 10 participants to watch and feel the behaviors, rate their valence, and explain their impressions. While a quantitative exploration of new and previous data showed correlation between multi-scale entropy and valence, the rich narratives revealed by thematic analysis of participant explanations call into question whether a single motion can, alone, be unambiguously valenced. Based on this evidence that people perceive robots as having inner lives, we recommend ways to build up narrative contexts over multiple interactions.","affective computing, social robots, emotion","","CHI '18"
"Conference Paper","Strohkorb Sebo S,Traeger M,Jung M,Scassellati B","The Ripple Effects of Vulnerability: The Effects of a Robot's Vulnerable Behavior on Trust in Human-Robot Teams","","2018","","","178–186","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","Chicago, IL, USA","2018","9781450349536","","https://doi.org/10.1145/3171221.3171275;http://dx.doi.org/10.1145/3171221.3171275","10.1145/3171221.3171275","Successful teams are characterized by high levels of trust between team members, allowing the team to learn from mistakes, take risks, and entertain diverse ideas. We investigated a robot's potential to shape trust within a team through the robot's expressions of vulnerability. We conducted a between-subjects experiment (N = 35 teams, 105 participants) comparing the behavior of three human teammates collaborating with either a social robot making vulnerable statements or with a social robot making neutral statements. We found that, in a group with a robot making vulnerable statements, participants responded more to the robot's comments and directed more of their gaze to the robot, displaying a higher level of engagement with the robot. Additionally, we discovered that during times of tension, human teammates in a group with a robot making vulnerable statements were more likely to explain their failure to the group, console team members who had made mistakes, and laugh together, all actions that reduce the amount of tension experienced by the team. These results suggest that a robot's vulnerable behavior can have ""ripple effects"" on their human team members' expressions of trust-related behavior.","trust, the ripple effect, groups and teams, human-robot interaction, social collaboration","","HRI '18"
"Conference Paper","Mahipala D,Parnichkun M","Development and Control of a Ball Riding Robot with a Pitch and Roll Controlled Inverted Pendulum","","2021","","","23–26","Association for Computing Machinery","New York, NY, USA","2021 International Conference on Robotics and Control Engineering","Tokyo, Japan","2021","9781450389471","","https://doi.org/10.1145/3462648.3462653;http://dx.doi.org/10.1145/3462648.3462653","10.1145/3462648.3462653","Ball riding robot is a robot with wheels which tries to balance on a ball by controlling the ball movement. Inverted pendulum is a device which uses an actuating cart to maintain the upright position. In this paper a ball riding robot is equipped with a pitch and roll planar inverted pendulum. Thus, the controller has to balance both ballbot body and the inverted pendulum by relying on the actuated movement of the ball driven by the Ballbot wheels. This paper explains the design and control of this novel dynamics system.","robot balancing, LQR control, ballbot, under-actuated system","","RobCE 2021"
"Conference Paper","Amioka S,Janssens R,Wolfert P,Ren Q,Pinto Bernal MJ,Belpaeme T","Limitations of Audiovisual Speech on Robots for Second Language Pronunciation Learning","","2023","","","359–367","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction","Stockholm, Sweden","2023","9781450399647","","https://doi.org/10.1145/3568162.3578633;http://dx.doi.org/10.1145/3568162.3578633","10.1145/3568162.3578633","The perception of audiovisual speech plays an important role in infants' first language acquisition and continues to be important for language understanding beyond infancy. Beyond that, the perception of speech and congruent lip motion supports language understanding for adults, and it has been suggested that second language learning benefits from audiovisual speech, as it helps learners distinguish speech sounds in the target language. In this paper, we study whether congruent audiovisual speech on a robot facilitates the learning of Japanese pronunciation. 27 native-Dutch speaking participants were trained in Japanese pronunciation by a social robot. The robot demonstrated 30 Japanese words of varying complexity using either congruent audiovisual speech, incongruent visual speech, or computer-generated audiovisual speech. Participants were asked to imitate the robot's pronunciation, recordings of which were rated by native Japanese speakers. Against expectation, the results showed that congruent audiovisual speech resulted in lower pronunciation performance than low-fidelity or incongruent speech. We show that our learners, being native Dutch speakers, are only very weakly sensitive to audiovisual Japanese speech which possibly explains why learning performance does not seem to benefit from audiovisual speech.","audiovisual speech, robot-assisted language learning, human-robot interaction, orofacial animations, multi-modal interaction","","HRI '23"
"Conference Paper","Nair SS,Sudheer AP,Joy ML","Design and Fabrication of River Cleaning Robot","","2020","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the Advances in Robotics 2019","Chennai, India","2020","9781450366502","","https://doi.org/10.1145/3352593.3352663;http://dx.doi.org/10.1145/3352593.3352663","10.1145/3352593.3352663","Environmental pollution is one of the most severe global threats that require suitable solutions to control air, soil and water pollution. Thus, the implementation of proper and innovative measures is a requisite for controlling pollution. More than two third of earth's crust is covered with water out of which less than 2.5 percent is available for human consumption. This fact makes it serious to check the cases of water pollution. Many of the initiatives are taken to control pollution such as manual and machine-based cleaning which needs human supervision all the time. The need of manual labour for removing waste can hazard the person. Therefore, a robot that cleans the waste autonomously from the water can make a significant impact on pollution control. However, the proper designing of such a robot is a challenging task. In this paper, the design and analysis of a river cleaning robot are explained. The mechanism is designed to perform different applications such as collecting the floating waste, underwater inspection, etc. The robot consists of a frame, cylindrical hull, thrusters and wide arms for waste disposal. The determination of hydrodynamic coefficients using ANSYS fluent solver, hydrodynamic modeling, static structural analysis, buckling analysis of hull and development of prototype are also included in this paper.","Hydrodynamic characteristics, ANSYS FLUENT, Solid Works, River cleaning","","AIR 2019"
"Conference Paper","Hayat AA,Sadanand RO,Saha SK","Robot Manipulation through Inverse Kinematics","","2015","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2015 Conference on Advances In Robotics","Goa, India","2015","9781450333566","","https://doi.org/10.1145/2783449.2783497;http://dx.doi.org/10.1145/2783449.2783497","10.1145/2783449.2783497","Inverse kinematics of a robot is very essential to find the joint variables that satisfy the desired pose of the robot during its manipulation. This is used in controlling the robot position, animation of the robot, etc. In this paper, step-by-step explanation and comparison of two widely used methods, namely, inverse kinematics and Jacobian inverse methods, for robot manipulation are presented. For this purpose a six degrees-of-freedom wrist-partitioned industrial robot KUKA KR5 Arc was used to illustrate the methods. A novel approach has been proposed for selecting the appropriate set of joint angles among the several inverse kinematic solutions. It is based on weight of each link and manipulability. The comparison of these approaches for linear and circular trajectory is presented. Their advantages, limitations, applications, and computations involved are also highlighted.","robot manipulation, inverse kinematics, jacobian, manipulability","","AIR '15"
"Conference Paper","Green HN,Islam MM,Ali S,Iqbal T","Who's Laughing NAO? Examining Perceptions of Failure in a Humorous Robot Partner","","2022","","","313–322","IEEE Press","Sapporo, Hokkaido, Japan","Proceedings of the 2022 ACM/IEEE International Conference on Human-Robot Interaction","","2022","","","","","Social robots are being deployed to interact with people in various scenarios, where they are expected to incorporate human-like conversational strategies to achieve fluency in interactions. For example, current robots are designed to perform advanced communication strategies (i.e., personal anecdotes, explanations, and apologies) to recover from task failure. However, these tactics are not always sufficient for failure recovery as they can be lengthy and insufficient for encouraging future interactions. In human-human interactions, people often use humor as a low-risk and engaging method for managing failures. Thus, the successful execution of advanced, human-like humor could enable robots to recover from task failures more efficiently. In this paper, we present a human-robot interaction study exploring how a robot's utilization of various human-like humor types (i.e., affiliative, aggressive, self-enhancing, and self-defeating) are perceived by human teammate (n=32) and an external observer of the interaction (n=256). Additionally, we have explored the effects of performance, humor type, perspective, and previous experience with robots on the participants' perceptions of warmth, competence, and the robot as a teammate. Our results indicate that dyadic participants rated the successful robot to be more competent and a better teammate than the bystander participants. Additionally, the results indicate that participants with less experience with robots found the successful robot to be more competent than participants with high levels of experience. These findings will enable the human-robot interaction community to develop more engaging robots for fluent interactive experiences in the future.","human-robot interaction, humor, recovery, failure","","HRI '22"
"Conference Paper","Zahedi Z,Verma M,Sreedharan S,Kambhampati S","Trust-Aware Planning: Modeling Trust Evolution in Iterated Human-Robot Interaction","","2023","","","281–289","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction","Stockholm, Sweden","2023","9781450399647","","https://doi.org/10.1145/3568162.3578628;http://dx.doi.org/10.1145/3568162.3578628","10.1145/3568162.3578628","Trust between team members is an essential requirement for any successful cooperation. Thus, engendering and maintaining the fellow team members' trust becomes a central responsibility for any member trying to not only successfully participate in the task but to ensure the team achieves its goals. The problem of trust management is particularly challenging in mixed human-robot teams where the human and the robot may have different models about the task at hand and thus may have different expectations regarding the current course of action, thereby forcing the robot to focus on the costly explicable behavior. We propose a computational model for capturing and modulating trust in such iterated human-robot interaction settings, where the human adopts a supervisory role. In our model, the robot integrates human's trust and their expectations about the robot into its planning process to build and maintain trust over the interaction horizon. By establishing the required level of trust, the robot can focus on maximizing the team goal by eschewing explicit explanatory or explicable behavior without worrying about the human supervisor monitoring and intervening to stop behaviors they may not necessarily understand. We model this reasoning about trust levels as a meta reasoning process over individual planning tasks. We additionally validate our model through a human subject experiment.","explainable ai, trust-aware decision-making, trustable ai, explicable planning","","HRI '23"
"Conference Paper","Ogasawara A,Gouko M","Stationery Holder Robot That Encourages Office Workers to Tidy Their Desks","","2017","","","439–441","Association for Computing Machinery","New York, NY, USA","Proceedings of the 5th International Conference on Human Agent Interaction","Bielefeld, Germany","2017","9781450351133","","https://doi.org/10.1145/3125739.3132581;http://dx.doi.org/10.1145/3125739.3132581","10.1145/3125739.3132581","To increase efficiency at work, it is important to keep the work space tidy. In this study, we propose a stationery holder robot to improve deskwork efficiency by reducing clutter. The robot is developed based on human-robot interactions, and it vibrates to remind and encourage workers to tidy their desks. First, we explain the concept of the robot and introduce a prototype. Then, we report the results of a preliminary experiment conducted to investigate the participants' intention to tidy up.","human robot interaction","","HAI '17"
"Conference Paper","van Straten CL,Peter J,Kühne R,de Jong C,Barco A","Technological and Interpersonal Trust in Child-Robot Interaction: An Exploratory Study","","2018","","","253–259","Association for Computing Machinery","New York, NY, USA","Proceedings of the 6th International Conference on Human-Agent Interaction","Southampton, United Kingdom","2018","9781450359535","","https://doi.org/10.1145/3284432.3284440;http://dx.doi.org/10.1145/3284432.3284440","10.1145/3284432.3284440","This study aimed to explore technological and interpersonal trust in interactions between children and social robots. Specifically, we focused on whether children distinguish between these two types of trust and whether the two constitute independent constructs or interact. Using an exploratory approach, we analyzed the explanations 87 children, aged 7 to 11 years, offered for the degree to which they indicated to trust a robot with which they had just interacted. Our results suggest that children distinguished between technological and interpersonal trust in a robot. Three main categories of answers could be identified: answers relating to technological trust, those indicating the presence of interpersonal trust, and a third category in which children referred to technological properties of robots as a reason for the existence of interpersonal trust. We discuss these findings in light of the development of child-robot relationships and the design of future child-robot interaction studies.","child-robot relationship formation, child-robot interaction, interpersonal trust, human-robot interaction, technological trust","","HAI '18"
"Journal Article","Norton A,Admoni H,Crandall J,Fitzgerald T,Gautam A,Goodrich M,Saretsky A,Scheutz M,Simmons R,Steinfeld A,Yanco H","Metrics for Robot Proficiency Self-Assessment and Communication of Proficiency in Human-Robot Teams","J.  Hum. -Robot Interact.","2022","11","3","","Association for Computing Machinery","New York, NY, USA","","","2022-07","","","https://doi.org/10.1145/3522579;http://dx.doi.org/10.1145/3522579","10.1145/3522579","As development of robots with the ability to self-assess their proficiency for accomplishing tasks continues to grow, metrics are needed to evaluate the characteristics and performance of these robot systems and their interactions with humans. This proficiency-based human-robot interaction (HRI) use case can occur before, during, or after the performance of a task. This article presents a set of metrics for this use case, driven by a four-stage cyclical interaction flow: (1) robot self-assessment of proficiency (RSA), (2) robot communication of proficiency to the human (RCP), (3) human understanding of proficiency (HUP), and (4) robot perception of the human’s intentions, values, and assessments (RPH). This effort leverages work from related fields including explainability, transparency, and introspection, by repurposing metrics under the context of proficiency self-assessment. Considerations for temporal level (a priori, in situ, and post hoc) on the metrics are reviewed, as are the connections between metrics within or across stages in the proficiency-based interaction flow. This article provides a common framework and language for metrics to enhance the development and measurement of HRI in the field of proficiency self-assessment.","performance evaluation, proficiency self-assessment, metrics, Human-robot interaction","",""
"Conference Paper","Masjutin L,Laing JK,Maier GW","Why Do We Follow Robots? An Experimental Investigation of Conformity with Robot, Human, and Hybrid Majorities","","2022","","","139–146","IEEE Press","Sapporo, Hokkaido, Japan","Proceedings of the 2022 ACM/IEEE International Conference on Human-Robot Interaction","","2022","","","","","Individuals tend to conform to a majority for reasons of peer pressure (normative conformity) and insecurity (informational conformity). It is important to investigate the reasons for social phenomena such as conformity in order to better understand processes in hybrid teams (i.e., teams which consist of humans and robots). Research has yielded conflicting results on conformity with robot and hybrid majorities, and the reasons for conformity remain unclear. We conducted a within-subject online experiment (n = 103) to compare the reasons for conformity under three conditions: human, robot, and hybrid majorities. Results indicate that subjects conformed most often with hybrid majorities, while they conformed least often with robot majorities. Normative conformity influenced conformity with human majorities, but informational conformity did not. Informational conformity influenced conformity with robot majorities, but normative conformity did not. Both types of conformity affected conformity with hybrid majorities. Our results provide a possible explanation for the heterogeneous findings on conformity in HRI","informational conformity, hybrid teams, social processes, asch paradigm, experiment, conformity, normative conformity","","HRI '22"
"Conference Paper","Hu S,Chew E","The Investigation and Novel Trinity Modeling for Museum Robots","","2021","","","21–28","Association for Computing Machinery","New York, NY, USA","Eighth International Conference on Technological Ecosystems for Enhancing Multiculturality","Salamanca, Spain","2021","9781450388504","","https://doi.org/10.1145/3434780.3436541;http://dx.doi.org/10.1145/3434780.3436541","10.1145/3434780.3436541","There have been interactive museum tour-guide robots under investigation since the end of twentieth century. However, those researches are limited to localisations and telepresence with less humanoids deployment or human-touched features. This research used a humanoid robot to develop the first Welsh-based museum robots that can speak bilingual, English and Welsh, addressing the design method, constraints and initial experimental results. This article introduces the definition and development of robots and service robots with three aims: 1) to design and pilot service robots in a public educational environment, National Museum of Wales, Cardiff. This is to develop a semi-autonomous robotic museum programme that can guide and educate visitors, explain exhibits and perform surveys based on a higher level of robot technology platform; 2) to perform voice interaction with the visitors and provides an inquiry and corporate branding services by the robotic programme with initial user experiences inquiry; and 3) to provide educational service robot design recommendation and a novel Trinity conceptual model and design principles to the sector based on the findings from objectives 1 and 2, for preliminary study and research on artificial intelligence in education and social cognition. Case study research method is used to lays a reference for museum robotic research, and it is easy to expand functionally, that is, secondary development; developing an autonomous humanoid robot for museum visit and interactive education.","Nao robot, Museum robot, educational robot, service robot","","TEEM'20"
"Journal Article","Asselborn T,Sharma K,Johal W,Dillenbourg P","Bridging Multilevel Time Scales in HRI: An Analysis Framework","J.  Hum. -Robot Interact.","2019","8","3","","Association for Computing Machinery","New York, NY, USA","","","2019-08","","","https://doi.org/10.1145/3338809;http://dx.doi.org/10.1145/3338809","10.1145/3338809","In this article, we present a multi-level time scales framework for the analysis of human-robot interaction (HRI). Such a framework allows HRI scientists to model the inter-relation between measures and factors of an experiment. Our final goal with the introduction of this framework is to unify scientific practice in the HRI community for better reproducibility. Our new approach transposes Newell’s framework of human actions to model human-robot interaction. Measures from the interaction are sorted into categories (time scales) corresponding to the temporal constraints proposed by Newell. According to this sorting, a bottom-up or top-down analysis can then be performed to correlate variables which allows a better understanding and explanation of the interaction. The utilization of our method within two experimental use cases is then presented. The first one, a child-robot interaction, involves two robots and one child playing a memory game. The second is based on an analysis of the PInSoRo dataset, involving 30 child-robot pairs in a freeplay interaction. Finally, we introduce clear guidelines to re-use the framework.","Newell’s time scale, HRI analysis framework, research reproducibility, multi-level time scale, guideline for variables sorting","",""
"Conference Paper","Craenen BG,Deshmukh A,Foster ME,Vinciarelli A","Shaping Gestures to Shape Personality: Big-Five Traits, Godspeed Scores and the Similarity-Attraction Effect","","2018","","","2221–2223","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems","Stockholm, Sweden","2018","","","","","This paper explores the role of personality as a mediation variable between observable behaviour of a robot - in this case, gestures of different energy and spatial extension - and the experience of its users according to the Godspeed questionnaire, a standard instrument for gathering subjective ratings of human-robot interaction. The results show that the personality traits that the users attribute to a robot are, to a certain extent, predictive of the subjective scores, i.e., of the quality of the interaction they have with it. Furthermore, the experiments show that 15 of the 30 observers involved in the experiments tend to like the robot more when they attribute traits to it that more similar to their own. The observation that only part of the observers display such a tendency - known as similarity-attraction effect - might explain why previous investigations of the same phenomenon have provided contradictory results.","automatic personality synthesis, gestures, godspeed scores, similarity-attraction effect","","AAMAS '18"
"Conference Paper","Kayukawa S,Sato D,Murata M,Ishihara T,Takagi H,Morishima S,Asakawa C","Enhancing Blind Visitor’s Autonomy in a Science Museum Using an Autonomous Navigation Robot","","2023","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems","Hamburg, Germany","2023","9781450394215","","https://doi.org/10.1145/3544548.3581220;http://dx.doi.org/10.1145/3544548.3581220","10.1145/3544548.3581220","Enabling blind visitors to explore museum floors while feeling the facility’s atmosphere and increasing their autonomy and enjoyment are imperative for giving them a high-quality museum experience. We designed a science museum exploration system for blind visitors using an autonomous navigation robot. Blind users can control the robot to navigate them toward desired exhibits while playing short audio descriptions along the route. They can also browse detailed explanations on their smartphones and call museum staff if interactive support is needed. Our real-world user study at a science museum during its opening hour revealed that blind participants could explore the museum safely and independently at their own pace. The study also showed that the sighted visitors who saw the participants walking with the robot accepted the assistive robot well. We finally conducted focus group sessions with the blind participants and discussed further requirements toward a more independent museum experience.","museum, autonomous navigation robot, blind navigation, Visual impairment","","CHI '23"
"Journal Article","Pelikan H,Hofstetter E","Managing Delays in Human-Robot Interaction","ACM Trans.  Comput. -Hum.  Interact.","2022","","","","Association for Computing Machinery","New York, NY, USA","","","2022-10","","1073-0516","https://doi.org/10.1145/3569890;http://dx.doi.org/10.1145/3569890","10.1145/3569890","Delays in the completion of joint actions are sometimes unavoidable. How should a robot communicate that it cannot immediately act or respond in a collaborative task? Drawing on video recordings of a face scanning activity in family homes, we investigate how humans make sense of a Cozmo robot’s delays on a moment-by-moment basis. Cozmo’s sounds and embodied actions are recognized as indicators of delay but encourage human participants to act in ways that undermine the scanning process. In comparing the robot’s delay management strategies with human-human vocal and embodied practices, we demonstrate key differences in the sequences that impact how the robot is understood. The study demonstrates how delay events are accomplished as embodied displays that are distributed across co-participants. We present a framework for making delay transparent through situated explanations, particularly in the form of non-lexical sounds and bodily actions.","system response time, embodiment, engagement, sound, conversation analysis, ethnomethodology, time delay","Just Accepted",""
"Conference Paper","Rakita D,Mutlu B,Gleicher M","Effects of Onset Latency and Robot Speed Delays on Mimicry-Control Teleoperation","","2020","","","519–527","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction","Cambridge, United Kingdom","2020","9781450367462","","https://doi.org/10.1145/3319502.3374838;http://dx.doi.org/10.1145/3319502.3374838","10.1145/3319502.3374838","In this paper, we study the effects of delays in a mimicry-control robot teleoperation interface which involves a user moving their arms to directly show the robot how to move and the robot follows in real time. Unlike prior work considering delays in other teleoperation systems, we consider delays due to robot slowness in addition to latency in the onset of movement commands. We present a human-subjects study that shows how different amounts and types of delays have different effects on task performance. We compare the movements under different delays to reveal the strategies that operators use to adapt to delay conditions and to explain performance differences. Our results show that users can quickly develop strategies to adapt to slowness delays but not onset latency delays. We discuss the implications of our results for the future development of methods designed to mitigate the effects of delays.","teleoperation, motion retargeting, latency analysis","","HRI '20"
"Conference Paper","Moriyama R,Taniguchi A,Serikawa S,Kitazono Y","Proposal of Automatic Sand Catcher Robot of Uniforms","","2023","","","60–64","Association for Computing Machinery","New York, NY, USA","Proceedings of the 9th International Conference on Applied Computing & Information Technology","Virtual Event, USA","2023","9781450397605","","https://doi.org/10.1145/3543895.3543943;http://dx.doi.org/10.1145/3543895.3543943","10.1145/3543895.3543943","Outdoor sports are very often dirty by practicing and playing matches. If you put the uniform that remains dirty in the washing machine as it is when washing such a dirty uniform and move it, sand and dust will get stuck in the washing machine and cause it to break down. Therefore, it is necessary to perform a process of washing down to remove the dirt of the sand attached to the surface by hand before putting it in the washing machine. There are many disadvantages such as rough or dirty hands when such underwashing is done manually. Therefore, we propose a robot that can automatically remove dirt from uniforms. We will explain how to use this robot. First fix the dirty uniform under this robot. Next, bring a small vacuum cleaner fixed to the robot servomotor to the top right of the uniform. Then clean the lower right of the uniform with a vacuum cleaner. By shifting this to the left side, you can remove the sand of the entire uniform. In addition, it is now possible to adjust the strength of the vacuum cleaner by connecting the conductor to the vacuum cleaner running with the battery and applying an appropriate voltage. In addition, it became a mechanism that can save electricity as much as possible by turning on the switch only when attached to the uniform in the program. By using this robot, you can automatically wash down without any disadvantages such as getting your hands dirty. In addition, time, human labor, electricity, etc. can be saved.","small vacuum, sand, uniforms","","ACIT '22"
"Conference Paper","Morimoto D,Even J,Kanda T","Can a Robot Handle Customers with Unreasonable Complaints?","","2020","","","579–587","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction","Cambridge, United Kingdom","2020","9781450367462","","https://doi.org/10.1145/3319502.3374830;http://dx.doi.org/10.1145/3319502.3374830","10.1145/3319502.3374830","The service industry is facing an increase in the number of malicious customers (customers with unreasonable complaints). Employees have reported that handling unreasonable complaints is particularly stressful. Considering the recent push for workplace automation, we should have robots handling this task in place of humans. We propose a robot behavioral model designed for handling unreasonable complaints. The robot with this model has to ""please the customer'' without proposing a settlement. From a large survey of Japanese workers conducted by labor unions and an interview survey of experienced workers we conducted, we identified the conventional complaint handling flow as 1) listen to the complaint, 2) confirm the content of the complaint, 3) apologize, 4) give an explanation, and 5) conclude. The proposed behavioral model is a variation of this flow that takes into account the ""state of mind'' of the customer. In particular, the robot with this model does not leave the first step and keeps asking questions until the customer is ""ready to listen''. We conducted a user study, using a Wizard-of-Oz approach, to compare the proposed behavioral model to a baseline one implementing the conventional flow. We replicated in our laboratory the situation of a customer in a mobile phone shop. The proposed behavioral model was significantly better at making the customers believe that the robot listened to them and tried to help.","user study, customer handling, service robotics","","HRI '20"
"Conference Paper","Jia T,Li C,Guan X,Ji L","Enhancing Engagement during Robot-Assisted Rehabilitation Integrated with Motor Imagery Task","","2019","","","12–16","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2019 International Conference on Intelligent Medicine and Health","Ningbo, China","2019","9781450372862","","https://doi.org/10.1145/3348416.3348420;http://dx.doi.org/10.1145/3348416.3348420","10.1145/3348416.3348420","Stroke remains the most common cause of motor deficits for adults. Enhancing engagement has become the focus of recent research with the aim of improving the efficiency of robot-assisted rehabilitation. Since motor imagery (MI) has the potential to engage the subject, the objective of this study is to explore the influence of complementing robot-assisted rehabilitation with MI during training exercises. An experiment was designed and conducted in which 10 healthy subjects were recruited to participate in two separate sessions. An acoustic-cue-based experimental paradigm was applied in both sessions. In the first session, each patient was required to imagine moving arm after the cue, then the robot device drove the arm during the MI process; while in the second session, the robotic device drove the user to move without requiring the MI tasks. Each session consisted of 20 trails, in which electroencephalogram (EEG) was recorded to analyze the activated brain regions. Analyses showed that the activation of sensorimotor cortex (SM1) was the strongest during passive movement (PM) integrated with MI than either PM or MI alone. The results indicated that robot-assisted training integrated with MI task can enhance the subject's engagement as shown by a stronger event related desynchronization (ERD), which can lead to a stronger stimulation on SM1. This indication can explain why only passive movement driven by robotic device has a low rehabilitation efficiency during clinical practice. The result can also contribute to the understanding of the mechanism underlying the brain computer interface (BCI) supported rehabilitation therapy, which can improve rehabilitation efficiency by closing the loop between the motor intention and sensorimotor feedback.","Motor rehabilitation, sensorimotor feedback, engagement, motor imagery","","ICIMH 2019"
"Conference Paper","Marchesi S,Spatola N,Perez-Osorio J,Wykowska A","Human vs Humanoid. A Behavioral Investigation of the Individual Tendency to Adopt the Intentional Stance","","2021","","","332–340","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction","Boulder, CO, USA","2021","9781450382892","","https://doi.org/10.1145/3434073.3444663;http://dx.doi.org/10.1145/3434073.3444663","10.1145/3434073.3444663","Humans interpret and predict behavior of others with reference to mental states or, in other words, by adopting the intentional stance. The present study investigated to what extent individuals adopt the intentional stance towards two agents (a humanoid robot and a human). We asked participants to judge whether two different descriptions fit the behaviors of the robot/human displayed in photographic scenarios. We measured acceptance/rejection rate of the descriptions (as an explicit measure) and response times in making the judgment (as an implicit measure). Our results show that at the explicit level, participants are more likely to use mentalistic descriptions for the human agent and mechanistic descriptions for the robot. Interestingly, at the implicit level, we found no difference in response times associated with the robotic agent. We argue that, at the implicit level, both stances are processed as ""equally likely"" to explain the behavior of a humanoid robot, while at the explicit level there is an asymmetry in the adopted stance. Furthermore, cluster analysis on participants' individual differences in anthropomorphism likelihood revealed that people with a high tendency to anthropomorphize tend to accept faster the mentalistic description. This suggests that the decisional process leading to adoption of one or the other stance to adopt is influenced by individual tendency to anthropomorphize non-human agents.","mental states, anthropomorphism, response times, human-robot interaction, intentional stance","","HRI '21"
"Journal Article","Kunold L,Bock N,Rosenthal-von der Pütten A","Not All Robots Are Evaluated Equally: The Impact of Morphological Features on Robots’ Assessment through Capability Attributions","J.  Hum. -Robot Interact.","2023","12","1","","Association for Computing Machinery","New York, NY, USA","","","2023-02","","","https://doi.org/10.1145/3549532;http://dx.doi.org/10.1145/3549532","10.1145/3549532","Favorable assessments of social robots are addressed in several research and development attempts because positive attitudes and intentions towards technology are regarded as a necessary prerequisite for usage. To predict a favorable evaluation, it is inevitable to understand the appraisal process and determine crucial variables that affect the evaluative and behavioral consequences of HRI. Robotic morphology has been identified as one of these variables. In the present work, we expand previous work by demonstrating that capability attributions associated with robots’ morphological features explain variations in evaluations. Based on two large picture-based online studies (Study 1, n = 673; Study 2, n = 586) we show that robots with similar morphological features (e.g., robots with arms and grippers) can be clustered along their assigned capabilities, and that these capabilities (e.g., to manipulate objects) explain evaluations of the robots in terms of acceptance and social attributes (i.e., warmth, competence, and discomfort). We discuss whether these initial assessments are relevant to live interactions and how our results can inform robot design.","Human-robot interaction, morphology, capability attributions, acceptance","",""
"Conference Paper","Khan S,Rabbani MR","Chatbot as Islamic Finance Expert (CaIFE): When Finance Meets Artificial Intelligence","","2021","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2020 4th International Symposium on Computer Science and Intelligent Control","Newcastle upon Tyne, United Kingdom","2021","9781450388894","","https://doi.org/10.1145/3440084.3441213;http://dx.doi.org/10.1145/3440084.3441213","10.1145/3440084.3441213","Artificial intelligence (AI) is the key technology in the new disruptive technological innovation and industrial transformation. AI has very wide application in finance and banking. The financial institutions not only answer the queries of the customers, but they should also clarify the complaints the customer face and provide the solution. For this purpose, many banks and financial institutions are using Chatbot to provide solution to customer complaints and queries. Chatbots are very efficient in providing solution to customers queries and are available 24 hours to give solution to customer's complaints. Finally, we propose an artificial Intelligence based interactive Chatbot called 'Chatbot as Islamic Finance Expert' (CaIFE). Our interactive Chatbot CaIFE receives automatic robot support related to Islamic finance and banking by having users communicate with a robot having knowledge accumulated by machine learning. It answers any query related to Islamic finance and banking on real time basis. It then presents a case study of CaIFE and explains its characteristics and limitations.","NLP, Financial Expert, machine learning, Islamic finance, Artificial Intelligence, Chatbot, Sharia","","ISCSIC 2020"
"Conference Paper","Druga S,Williams R,Park HW,Breazeal C","How Smart Are the Smart Toys? Children and Parents' Agent Interaction and Intelligence Attribution","","2018","","","231–240","Association for Computing Machinery","New York, NY, USA","Proceedings of the 17th ACM Conference on Interaction Design and Children","Trondheim, Norway","2018","9781450351522","","https://doi.org/10.1145/3202185.3202741;http://dx.doi.org/10.1145/3202185.3202741","10.1145/3202185.3202741","Intelligent toys and smart devices are becoming ubiquitous in children's homes. As such, it is imperative to understand how these computational objects impact children's development. Children's attribution of intelligence relates to how they perceive the behavior of these agents [6]. However, their underlying reasoning is not well understood. To explore this, we invited 30 pairs of children (4--10 years old) and their parents to assess the intelligence of mice, robots, and themselves in a maze-solving activity. Participants watched videos of mice and robots solving a maze. Then, they solved the maze by remotely navigating a robot. Solving the maze enabled participants to gain insight into the agent's mind by referencing their own experience. Children and their parents gave similar answers for whether the mouse or the robot was more intelligent and used a wide variety of explanations. We also observed developmental differences in childrens' references to agents' social-emotional attributes, strategies and performance.","intelligence attribution, parental influence, child-agent interaction, child-robot interaction","","IDC '18"
"Conference Paper","Złotowski J,Bartneck C","The Inversion Effect in HRI: Are Robots Perceived More like Humans or Objects?","","2013","","","365–372","IEEE Press","Tokyo, Japan","Proceedings of the 8th ACM/IEEE International Conference on Human-Robot Interaction","","2013","9781467330558","","","","The inversion effect describes a phenomenon in which certain types of images are harder to recognize when they are presented upside down compared to when they are shown upright. Images of human faces and bodies suffer from the inversion effect whereas images of objects do not. The effect may be caused by the configural processing of faces and body postures, which is dependent on the perception of spatial relations between different parts of the stimuli. We investigated if the inversion effect applies to images of robots in the hope of using it as a measurement tool for robot's anthropomorphism. The results suggest that robots, similarly to humans, are subject to the inversion effect. Furthermore, there is a significant, but weak linear relationship between the recognition accuracy and perceived anthropomorphism. The small variance explained by the inversion effect renders this test inferior to the questionnaire based Godspeed Anthropomorphism Scale.","anthropomorphism, human-robot interaction, methodology, inversion effect","","HRI '13"
"Conference Paper","Esterwood C,Robert LP","Having the Right Attitude: How Attitude Impacts Trust Repair in Human-Robot Interaction","","2022","","","332–341","IEEE Press","Sapporo, Hokkaido, Japan","Proceedings of the 2022 ACM/IEEE International Conference on Human-Robot Interaction","","2022","","","","","Robot co-workers, like human co-workers, make mistakes that undermine trust. Yet, trust is just as important in promoting human-robot collaboration as it is in promoting human-human collaboration. In addition, individuals can significantly differ in their attitudes toward robots, which can also impact or hinder their trust in robots. To better understand how individual attitude can influence trust repair strategies, we propose a theoretical model that draws from the theory of cognitive dissonance. To empirically verify this model, we conducted a between-subjects experiment with 100 participants assigned to one of four repair strategies (apologies, denials, explanations, or promises) over three trust violations. Individual attitudes did moderate the efficacy of repair strategies and this effect differed over successive trust violations. Specifically, repair strategies were most effective relative to individual attitude during the second of the three trust violations, and promises were the trust repair strategy most impacted by an individual's attitude.","trust repair, attitude, awor, human-robot interaction","","HRI '22"
"Conference Paper","Han Z,Williams T","A Task Design for Studying Referring Behaviors for Linguistic HRI","","2022","","","783–786","IEEE Press","Sapporo, Hokkaido, Japan","Proceedings of the 2022 ACM/IEEE International Conference on Human-Robot Interaction","","2022","","","","","In many domains, robots must be able to communicate to humans through natural language. One of the core capabilities needed for task-based natural language communication is the ability to refer to objects, people, and locations. Existing work on robot referring expression generation has focused nearly exclusively on generation of definite descriptions to visible objects. But humans use many other linguistic forms to refer (e.g., pronouns) and commonly refer to objects that cannot be seen at time of reference. Critically, existing corpora used for modeling robot referring expression generation are insufficient for modeling this wider array of referring phenomena. To address this research gap, we present a novel interaction task in which an instructor teaches a learner in a series of construction tasks that require repeated reference to a mixture of present and non-present objects. We further explain how this task could be used in principled data collection efforts.","data collection, dyadic interactions, human-robot interaction, linguistic hri, referring form selection","","HRI '22"
"Conference Paper","Liu D,He J,Hu Q","A Study on the Application of Digital Twin Technology in Speed Monitoring of Ultrasonic Motor","","2021","","","406–410","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2020 2nd International Conference on Big Data and Artificial Intelligence","Johannesburg, South Africa","2021","9781450376457","","https://doi.org/10.1145/3436286.3436427;http://dx.doi.org/10.1145/3436286.3436427","10.1145/3436286.3436427","With its unique advantages, ultrasonic motors are favored in aerospace, robotics, automation equipment, precision instrumentation, etc. Aiming at the phenomenon of unstable motor speed caused by the influence of ultrasonic motor's material properties, wear, and environmental factors, this paper proposes the use of digital twin technology to carry out dynamic real-time monitoring of ultrasonic motor. Based on the analysis of the operation mechanism and control mode of the ultrasonic motor, and the digital twin technology, a digital twin model of the ultrasonic motor is constructed, and the realization process of the digital twin ultrasonic motor speed monitoring is explained.","Digital twin, Ultrasonic motor, Rotation speed monitoring","","ISBDAI '20"
"Journal Article","Young JE,Igarashi T,Sharlin E,Sakamoto D,Allen J","Design and Evaluation Techniques for Authoring Interactive and Stylistic Behaviors","ACM Trans. Interact. Intell. Syst.","2014","3","4","","Association for Computing Machinery","New York, NY, USA","","","2014-01","","2160-6455","https://doi.org/10.1145/2499671;http://dx.doi.org/10.1145/2499671","10.1145/2499671","We present a series of projects for end-user authoring of interactive robotic behaviors, with a particular focus on the style of those behaviors: we call this approach Style-by-Demonstration (SBD). We provide an overview introduction of three different SBD platforms: SBD for animated character interactive locomotion paths, SBD for interactive robot locomotion paths, and SBD for interactive robot dance. The primary contribution of this article is a detailed cross-project SBD analysis of the interaction designs and evaluation approaches employed, with the goal of providing general guidelines stemming from our experiences, for both developing and evaluating SBD systems. In addition, we provide the first full account of our Puppet Master SBD algorithm, with an explanation of how it evolved through the projects.","Style-by-demonstration, human-computer interaction, human-robot interaction, programming-by-demonstration","",""
"Conference Paper","Smedegaard CV","Reframing the Role of Novelty within Social HRI: From Noise to Information","","2020","","","411–420","IEEE Press","Daegu, Republic of Korea","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","","2020","9781538685556","","","","Social robots, understood as the category of embodied robots extending into social domains through reciprocal social interaction, are still a practical novelty in most of these domains today. However, the phenomenon of novelty effects is only eclectically and peripherally addressed within most research into social human-robot interaction, and even when treated more extensively, it is usually framed as a source of noise in need of reduction. In this paper, I will argue a reframing of novelty effects that posits the phenomenon as a valuable source of information. In the first part of the paper, I present a tentative account of what I call experiential novelty in order to illustrate (1) that novelty should be understood as an 'original feature of experience', (2) that novelty arises in the engagement between an experiencer and an experience where the experiencer's possessed knowledge is inadequate in making sense of the experience, and (3) that novelty effects should be seen as cognitive and behavioural expressions of a 'search for meaning'. In the latter part of the paper, I discuss some of the current research lines within social human-robot interaction research from the perspective of this account of novelty. Most notably, I argue that retrospectively, the account holds explanatory utility in analyzing many of the findings in this research-field, and prospectively, the account holds generative utility in pointing to new ways in which participant experiences of novelty may be employed in research.","experiential novelty, social human-robot interaction, expectations, sense-making, novelty effects, social robots, engagement, learning, familiarization","","HRI '19"
"Conference Paper","Papoutsakis K,Padeleris P,Ntelidakis A,Stefanou S,Zabulis X,Kosmopoulos D,Argyros AA","Developing Visual Competencies for Socially Assistive Robots: The HOBBIT Approach","","2013","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 6th International Conference on PErvasive Technologies Related to Assistive Environments","Rhodes, Greece","2013","9781450319737","","https://doi.org/10.1145/2504335.2504395;http://dx.doi.org/10.1145/2504335.2504395","10.1145/2504335.2504395","In this paper, we present our approach towards developing visual competencies for socially assistive robots within the framework of the HOBBIT project. We show how we integrated several vision modules using a layered architectural scheme. Our goal is to endow the mobile robot with visual perception capabilities so that it can interact with the users. We present the key modules of independent motion detection, object detection, body localization, person tracking, head pose estimation and action recognition and we explain how they serve the goal of natural integration of robots in social environments.","tracking, action recognition, head pose estimation, object detection","","PETRA '13"
"Conference Paper","Wiedemeyer T,Bálint-Benczédi F,Beetz M","Pervasive 'Calm' Perception for Autonomous Robotic Agents","","2015","","","871–879","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems","Istanbul, Turkey","2015","9781450334136","","","","A major bottleneck in the realization of autonomous robotic agents performing complex manipulation tasks are the requirements that these tasks impose onto perception mechanisms. There is a strong need to scale robot perception capabilities along two dimensions: First, the variations of appearances and perceptual properties that real-world objects exhibit. Second, the variety of perceptual tasks, like categorizing and localizing, decomposing objects into their functional parts, perceiving the affordances they provide.This paper, addresses this need by organizing perception into a two-stage process. First, a pervasive and 'calm' perceptual component runs continually and interprets the incoming image stream to form a general purpose hybrid (symbolic/sub-symbolic) belief state. This is used by the second component, the task-directed perception subsystem, to perform the respective perception tasks in a more informed way. We describe and discuss the first component and explain how it can manage realistic belief states, form a memory of past perceptual experiences, and compute valuable perceptual attributes without delaying plan execution. It does so by exploiting that perception is not a one-shot task but rather a secondary task that is pervasively and calmly performed throughout the lifetime of the robot. We show system operating on a leading-edge manipulation platform.","lifelong learning, robot perception, pervasive perception, task dependency","","AAMAS '15"
"Conference Paper","Okundaye O,Quek F,Chu S","Broadening Participation for Remote Communities: Situated Distance Telepresence","","2019","","","494–500","Association for Computing Machinery","New York, NY, USA","Proceedings of the 18th ACM International Conference on Interaction Design and Children","Boise, ID, USA","2019","9781450366908","","https://doi.org/10.1145/3311927.3325318;http://dx.doi.org/10.1145/3311927.3325318","10.1145/3311927.3325318","Our work is concerned with how embodied communication involving speech and gestures may be mediated through mobile tele-robotics and augmented reality to support hands-on distance mentoring. Following work in the psycholinguistics of embodied communication (e.g., meaning is expressed through gesture, gaze, and speech), a four design-implement-test-deploy-evaluate study was undertaken. We investigated whether and how powerful multimodal language to support explanation and mentoring may be mediated over distance through the designs.","Public School, Micro-Manufacture, Communities of Practice, Maker Movement, Apprenticeship, Zone of Proximal Development","","IDC '19"
"Journal Article","Ore JP,Detweiler C,Elbaum S","An Empirical Study on Type Annotations: Accuracy, Speed, and Suggestion Effectiveness","ACM Trans. Softw. Eng. Methodol.","2021","30","2","","Association for Computing Machinery","New York, NY, USA","","","2021-02","","1049-331X","https://doi.org/10.1145/3439775;http://dx.doi.org/10.1145/3439775","10.1145/3439775","Type annotations connect variables to domain-specific types. They enable the power of type checking and can detect faults early. In practice, type annotations have a reputation of being burdensome to developers. We lack, however, an empirical understanding of how and why they are burdensome. Hence, we seek to measure the baseline accuracy and speed for developers making type annotations to previously unseen code. We also study the impact of one or more type suggestions. We conduct an empirical study of 97 developers using 20 randomly selected code artifacts from the robotics domain containing physical unit types. We find that subjects select the correct physical type with just 51% accuracy, and a single correct annotation takes about 2 minutes on average. Showing subjects a single suggestion has a strong and significant impact on accuracy both when correct and incorrect, while showing three suggestions retains the significant benefits without the negative effects. We also find that suggestions do not come with a time penalty. We require subjects to explain their annotation choices, and we qualitatively analyze their explanations. We find that identifier names and reasoning about code operations are the primary clues for selecting a type. We also examine two state-of-the-art automated type annotation systems and find opportunities for their improvement.","robotic systems, program analysis, dimensional analysis, physical units, automated static analysis, annotations, Type checking, software reliability","",""
"Journal Article","Nunez-Varela J,Wyatt JL","Models of Gaze Control for Manipulation Tasks","ACM Trans. Appl. Percept.","2013","10","4","","Association for Computing Machinery","New York, NY, USA","","","2013-10","","1544-3558","https://doi.org/10.1145/2536764.2536767;http://dx.doi.org/10.1145/2536764.2536767","10.1145/2536764.2536767","Human studies have shown that gaze shifts are mostly driven by the current task demands. In manipulation tasks, gaze leads action to the next manipulation target. One explanation is that fixations gather information about task relevant properties, where task relevance is signalled by reward. This work presents new computational models of gaze shifting, where the agent imagines ahead in time the informational effects of possible gaze fixations. Building on our previous work, the contributions of this article are: (i) the presentation of two new gaze control models, (ii) comparison of their performance to our previous model, (iii) results showing the fit of all these models to previously published human data, and (iv) integration of a visual search process. The first new model selects the gaze that most reduces positional uncertainty of landmarks (Unc), and the second maximises expected rewards by reducing positional uncertainty (RU). Our previous approach maximises the expected gain in cumulative reward by reducing positional uncertainty (RUG). In experiment ii the models are tested on a simulated humanoid robot performing a manipulation task, and each model's performance is characterised by varying three environmental variables. This experiment provides evidence that the RUG model has the best overall performance. In experiment iii, we compare the hand-eye coordination timings of the models in a robot simulation to those obtained from human data. This provides evidence that only the models that incorporate both uncertainty and reward (RU and RUG) match human data.","Decision making, reinforcement learning, gaze control","",""
"Conference Paper","Yvon S,Feeley M","A Small Scheme VM, Compiler, and REPL in 4k","","2021","","","14–24","Association for Computing Machinery","New York, NY, USA","Proceedings of the 13th ACM SIGPLAN International Workshop on Virtual Machines and Intermediate Languages","Chicago, IL, USA","2021","9781450391092","","https://doi.org/10.1145/3486606.3486783;http://dx.doi.org/10.1145/3486606.3486783","10.1145/3486606.3486783","Compact language implementations are increasingly popular for use in resource constrained environments. For embedded applications such as robotics and home automation, it is useful to support a Read-Eval-Print-Loop (REPL) so that a basic level of interactive development is possible directly on the device. Due to its minimalistic design, the Scheme language is particularly well suited for such applications and several implementations are available with different tradeoffs. In this paper we explain the design and implementation of Ribbit, a compact Scheme system that supports a REPL, is extensible and has a 4 KB executable code footprint.","Read-Eval-Print-Loop, Compiler, Virtual Machines, Small Footprint, Scheme, Dynamic Languages","","VMIL 2021"
"Conference Paper","Elyasaf A,Sadon A,Weiss G,Yaacov T","Using Behavioural Programming with Solver, Context, and Deep Reinforcement Learning for Playing a Simplified RoboCup-Type Game","","2021","","","243–251","IEEE Press","Munich, Germany","Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems","","2021","9781728151250","","https://doi.org/10.1109/MODELS-C.2019.00039;http://dx.doi.org/10.1109/MODELS-C.2019.00039","10.1109/MODELS-C.2019.00039","We describe four scenario-based implementations of controllers for a player in a simplified RoboCup-type game. All four implementations are based on the behavioural programming (BP) approach. We first describe a simple controller for the player using the state-of-the-art BPjs tool and then show how it can be extended in various ways. The first extension is based on a version of BP where the Z3 SMT solver is used to provide mechanisms for richer composition of modules within the BP model. This allows for modules with higher cohesion and lower coupling. It also allows incrementality: we could use the scenarios we developed for the challenge of MDETOOLS'18 and extend the model to handle the new system. The second extension of BP demonstrated in this paper is a set of idioms for subjecting model components to context. One of the differences between this year's challenge and the challenge we dealt with last year is that following the ball is not the only task that a player needs to handle, there is much more to care for. We demonstrate how we used the idioms for handling context to parametrize scenarios like ""go to a target"" in a dynamic and natural fashion such that modelers can efficiently specify reusable components similar to the way modern user manuals for advanced products are written. Lastly, in an attempt to make the instructions to the robot even more natural, we demonstrate a third extension based on deep reinforcement learning. Towards substantiating the observation that it is easier to explain things to an intelligent agent than to dumb compiler, we demonstrate how the combination of BP and deep reinforcement learning (DRL) allows for giving abstract instructions to the robot and for teaching it to follow them after a short training session.","","","MODELS '19"
"Conference Paper","Wang Y,Yu X,Yu C,Fan Z","Improved Motion Planning Algorithms Based on Rapidly-Exploring Random Tree: A Review","","2023","","","1–8","Association for Computing Machinery","New York, NY, USA","Proceedings of the 8th International Conference on Communication and Information Processing","Beijing, China","2023","9781450397100","","https://doi.org/10.1145/3571662.3571663;http://dx.doi.org/10.1145/3571662.3571663","10.1145/3571662.3571663","This paper mainly summarizes and introduces the improvements proposed by scholars at home and abroad in recent years for the application of Rapidly-exploring Random Tree in robot arms. This paper first briefly introduces the existing path planning algorithms and expounds their advantages and disadvantages. Then the principle and process of Rapidly-exploring Random Tree are described and the RRT algorithm in three-dimensional space is simulated and analyzed. Next, the improved RRT algorithm proposed by domestic and foreign researchers is classified, analyzed and explained. Finally, the whole article is summarized and the direction of future development and research of manipulator motion planning algorithms is prospected.","manipulator, path planning, RRT algorithm, improved RRT algorithm","","ICCIP '22"
"Conference Paper","Mikaiel A,Miao L","Implementation of a Self-Balancing Robot Using LEGO EV3 Robotic Kit and EV3DEV","","2018","","","154–158","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2nd International Conference on Advances in Image Processing","Chengdu, China","2018","9781450364607","","https://doi.org/10.1145/3239576.3239624;http://dx.doi.org/10.1145/3239576.3239624","10.1145/3239576.3239624","This paper discusses an educational project, in which we use LEGO Mindstorms EV3 and embedded programming to implement a self-balancing and line-following robot. In particular, we use the open source EV3DEV programming environment to write Python programs to get data from the sensors and control the motors. The benefit of our approach is that the students can solely focus on implementing the required PID controller and the corresponding parameter tuning, without the need of having to do mechanical and electrical design. We explain in the paper in details about the system setup, software development, and testing and verification. The outcomes of this paper can be very helpful to other educational and research projects that utilize the Lego EV3 robotic kits for learning and discovery purposes.","PID, EV3DEV, robotics, Embedded Software, LEGO Mindstorms EV3","","ICAIP '18"
"Conference Paper","Tarapore D,Christensen AL,Lima PU,Carneiro J","Abnormality Detection in Multiagent Systems Inspired by the Adaptive Immune System","","2013","","","23–30","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 2013 International Conference on Autonomous Agents and Multi-Agent Systems","St. Paul, MN, USA","2013","9781450319935","","","","Fault tolerance is one of the most prominent challenges in the field of multirobot systems. The efficient and long term operation of a robot collective requires an accurate detection and accommodation of abnormally behaving robots. Most of the existing fault tolerant systems prescribe a characterization of normal behavior, and train a model to recognize them. Behaviors not recognized by the model are labelled abnormal. However, these models require a priori knowledge of the normal behavior. Furthermore, multirobot systems employing these models do not transition well to scenarios involving temporal changes to normal behavior. We propose to address this challenging problem by taking inspiration from the regulation of tolerance and (auto)immunity in the adaptive immune system. We adopt the Crossregulation model, used to explain the robust immunological maintenance of tolerance, and deploy it within a multiagent system. Results of extensive simulation-based experiments demonstrate that a distributed multiagent system can detect abnormalities under varying conditions of normal behaviors. The collective dynamics gives rise to a meaningful normal-abnormal classification of the behavior by individual agents, even if these categories were not prescribed a priori in the agents.","decentralized control, multirobot systems, swarm robotics, crossregulation model, fault detection","","AAMAS '13"
"Conference Paper","Forman J,Tabb T,Do Y,Yeh MH,Galvin A,Yao L","ModiFiber: Two-Way Morphing Soft Thread Actuators for Tangible Interaction","","2019","","","1–11","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems","Glasgow, Scotland Uk","2019","9781450359702","","https://doi.org/10.1145/3290605.3300890;http://dx.doi.org/10.1145/3290605.3300890","10.1145/3290605.3300890","Despite thin-line actuators becoming widely adopted in different Human-Computer Interaction (HCI) contexts, including integration into fabrics, paper art, hinges, soft robotics, and human hair, accessible line-based actuators are very limited beyond shape memory alloy (SMA) wire and motor-driven passive tendons. In this paper, we introduce a novel, yet simple and accessible, line-based actuator. ModiFiber is a twisted-then-coiled nylon thread actuator with a silicone coating. This composite thread actuator exhibits unique two-way reversible shrinking or twisting behaviors triggered by heat or electrical current (i.e., Joule heating). ModiFiber is soft, flexible, safe to operate and easily woven or sewn, hence it has a great potential as an embedded line-based actuator for HCI purposes. In this paper, we explain the material mechanisms and manufacturing approaches, followed by some performance tests and application demonstrations.","artificial muscles, linear actuator, coiled thread actuators, twisting actuator, shrinking actuator, torsional actuator, reversibility, soft actuator, thread actuators","","CHI '19"
"Conference Paper","Atkin K,Licato J,Bringsjord S","Modeling Interoperability between a Reflex and Reasoning System in a Physical Simulation Environment","","2015","","","5–6","Society for Computer Simulation International","San Diego, CA, USA","Proceedings of the Poster Session and Student Colloquium Symposium","Alexandria, Virginia","2015","9781510801035","","","","When modeling the behavior of a cognitive agent in either a simulation or a real-world robotics scenario, often a choice must be made between two types of processes: an explicit, typically slow, and deliberative mode of reasoning; and a quick, automatic reflex system. This roughly corresponds to several well-known distinctions in the cognitive-psychology literature: System 1 vs. System 2, explicit vs. implicit, etc. However, the complex interaction between these processes is not sufficiently explored in computational simulations. We present PAGI (Psychometric Artificial General Intelligence) World, an open-sourced simulation environment that can represent both types of processes, and we discuss how the higher-level reasoning processes can interact with the lower-level reflexes of a cognitive agent, in such a way as to complement each other. We explain motivations for this interactivity, and describe our system for addressing it.","physics, unity, PAGI world, reflexes, DCEC","","Posters '15"
"Conference Paper","Chakraborti T,Sreedharan S,Kambhampati S","Explicability versus Explanations in Human-Aware Planning","","2018","","","2180–2182","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems","Stockholm, Sweden","2018","","","","","Human aware planning requires an agent to be aware of the mental model of the human in the loop during its decision process. This can involve generating plans that are explicable to the human as well as the ability to provide explanations when such plans cannot be generated. In this paper, we bring these two concepts together and show how an agent can account for both these needs and achieve a trade-off during the plan generation process itself by means of a model-space search method MEGA*. This provides a revised perspective of what it means for an AI agent to be ""human-aware"" by bringing together recent works on explicable planning and plans explanations under the umbrella of a single plan generation process. We illustrate these concepts using a robot involved in a typical search and reconnaissance task with an external supervisor.","plan explanations, human-aware planning, model reconciliation, argumentation, plan explicability","","AAMAS '18"
"Conference Paper","Ren Y,Cedeno-Mieles V,Hu Z,Deng X,Adiga A,Barrett C,Ekanayake S,Goode BJ,Korkmaz G,Kuhlman CJ,Machi D,Marathe MV,Ramakrishnan N,Ravi SS,Saraf P,Self N,Contractor N,Epstein J,Macy MW","Generative Modeling of Human Behavior and Social Interactions Using Abductive Analysis","","2020","","","413–420","IEEE Press","Barcelona, Spain","Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining","","2020","9781538660515","","","","Abduction is an inference approach that uses data and observations to identify plausible (and preferably, best) explanations for phenomena. Applications of abduction (e.g., robotics, genetics, image understanding) have largely been devoid of human behavior. Here, we devise and execute an iterative abductive analysis process that is driven by the social sciences: behaviors and interactions among groups of human subjects. One goal is to understand intra-group cooperation and its effect on fostering collective identity. We build an online game platform; perform and analyze controlled laboratory experiments; form hypotheses; build, exercise, and evaluate network-based agent-based models; and evaluate the hypotheses in multiple abductive iterations, improving our understanding as the process unfolds. While the experimental results are of interest, the paper's thrust is methodological, and indeed establishes the potential of iterative abductive looping for the (computational) social sciences.","","","ASONAM '18"
"Conference Paper","Dau HA,Keogh E","Matrix Profile V: A Generic Technique to Incorporate Domain Knowledge into Motif Discovery","","2017","","","125–134","Association for Computing Machinery","New York, NY, USA","Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","Halifax, NS, Canada","2017","9781450348874","","https://doi.org/10.1145/3097983.3097993;http://dx.doi.org/10.1145/3097983.3097993","10.1145/3097983.3097993","Time series motif discovery has emerged as perhaps the most used primitive for time series data mining, and has seen applications to domains as diverse as robotics, medicine and climatology. There has been recent significant progress on the scalability of motif discovery. However, we believe that the current definitions of motif discovery are limited, and can create a mismatch between the user's intent/expectations, and the motif discovery search outcomes. In this work, we explain the reasons behind these issues, and introduce a novel and general framework to address them. Our ideas can be used with current state-of-the-art algorithms with virtually no time or space overhead, and are fast enough to allow real-time interaction and hypotheses testing on massive datasets. We demonstrate the utility of our ideas on domains as diverse as seismology and epileptic seizure monitoring.","time series, interactive data mining, matrix profile, motif discovery","","KDD '17"
"Conference Paper","Liao YC,Todi K,Acharya A,Keurulainen A,Howes A,Oulasvirta A","Rediscovering Affordance: A Reinforcement Learning Perspective","","2022","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems","New Orleans, LA, USA","2022","9781450391573","","https://doi.org/10.1145/3491102.3501992;http://dx.doi.org/10.1145/3491102.3501992","10.1145/3491102.3501992","Affordance refers to the perception of possible actions allowed by an object. Despite its relevance to human–computer interaction, no existing theory explains the mechanisms that underpin affordance-formation; that is, how affordances are discovered and adapted via interaction. We propose an integrative theory of affordance-formation based on the theory of reinforcement learning in cognitive sciences. The key assumption is that users learn to associate promising motor actions to percepts via experience when reinforcement signals (success/failure) are present. They also learn to categorize actions (e.g., “rotating” a dial), giving them the ability to name and reason about affordance. Upon encountering novel widgets, their ability to generalize these actions determines their ability to perceive affordances. We implement this theory in a virtual robot model, which demonstrates human-like adaptation of affordance in interactive widgets tasks. While its predictions align with trends in human data, humans are able to adapt affordances faster, suggesting the existence of additional mechanisms.","Theory, Robotics, Reinforcement Learning, Adaptation, Perception, Machine Learning, Action, Interaction, Motion Planning, Design, Modeling, Affordance","","CHI '22"
"Conference Paper","Paradeda RB,Martinho C,Paiva A","Persuasion Strategies Using a Social Robot in an Interactive Storytelling Scenario","","2020","","","69–77","Association for Computing Machinery","New York, NY, USA","Proceedings of the 8th International Conference on Human-Agent Interaction","Virtual Event, USA","2020","9781450380546","","https://doi.org/10.1145/3406499.3415084;http://dx.doi.org/10.1145/3406499.3415084","10.1145/3406499.3415084","The behaviour of a person in a given situation can be explained understanding his personality traits. In this sense, the identification of these traits can be a great value to achieve personalised social influence. Although there are several models of persuasion, few of them take into account the person's personality traits. For this reason, this work describes a persuasion study that takes into account a person's personality. We develop a storytelling decision-making scenario, where the participant receives influencing messages to follow a pattern of behaviour determined by a persuasive agent (an autonomous social robot with assertive behaviour). From the study, we find evidence that the model used within the proposed scenario managed to make participants more engaged in the activity. We found pieces of evidence that the levels of assertiveness of a person can influence their attitude and perception by an agent. Also, we identify that persuasion strategy which uses persuasive arguments are more efficient than strategies that have no arguments. Finally, our proposed persuasion strategies have achieved a good level of successful influence.","persuasion, human-robot interaction, storytelling, mbti, personality","","HAI '20"
"Conference Paper","Puranic A,Deshmukh J,Nikolaidis S","Poster Abstract: Learning from Demonstrations with Temporal Logics","","2022","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 25th ACM International Conference on Hybrid Systems: Computation and Control","Milan, Italy","2022","9781450391962","","https://doi.org/10.1145/3501710.3524914;http://dx.doi.org/10.1145/3501710.3524914","10.1145/3501710.3524914","Learning-from-demonstrations (LfD) is a popular paradigm to obtain effective robot control policies for complex tasks via reinforcement learning without the need to explicitly design reward functions. However, it is susceptible to imperfections in demonstrations and also raises concerns of safety and interpretability in the learned control policies. To address these issues, we propose to use Signal Temporal Logic (STL) to express high-level robotic tasks and use its quantitative semantics to evaluate and rank the quality of demonstrations. Temporal logic-based specifications allow us to create non-Markovian rewards, and are also capable of defining interesting causal dependencies between tasks such as sequential task specifications. We present our completed work that proposed LfD-STL framework that learns from even suboptimal/imperfect demonstrations and STL specifications to infer rewards for reinforcement learning tasks. We have validated our approach through various experimental setups to show how our method outperforms prior LfD methods. We then discuss future directions for tackling the problem of explainability and interpretability in such learning-based systems.","temporal logic, demonstrations, imitation, reinforcement learning, reward inference","","HSCC '22"
"Conference Paper","Abrams AM,Dautzenberg PS,Jakobowsky C,Ladwig S,Rosenthal-von der Pütten AM","A Theoretical and Empirical Reflection on Technology Acceptance Models for Autonomous Delivery Robots","","2021","","","272–280","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction","Boulder, CO, USA","2021","9781450382892","","https://doi.org/10.1145/3434073.3444662;http://dx.doi.org/10.1145/3434073.3444662","10.1145/3434073.3444662","In this work, we provide an argument and first empirical insights that existing technology acceptance models fall short when it comes to explaining spontaneous, unplanned and unsolicited encounters between humans and delivery robots on the street. Since technology acceptance models have been defined by the technology's perceived ease of use, perceived usefulness and behavioural intention to use, they are not well suited to explain acceptance in situations in which humans meet robots without any prior intention to use. Nevertheless, acceptance of delivery robots might be a driving force for safe navigation. Thus, the concept of acceptance should not be limited to its current focus on (planned) usage. In consequence, we i) expand the understanding of technology acceptance, ii) propose the concept of Existence Acceptance for autonomous systems, and iii) explore a new model for acceptance in an online study (n = 185). Theoretical considerations hint towards the relevance of existence acceptance models for autonomous systems.","incops, ea, technology acceptance model, autonomous vehicle, acceptance, technology acceptance, autonomous robot, existence acceptance, delivery robot, tam","","HRI '21"
"Conference Paper","Rodríguez A,Rutle A,Kristensen LM,Durán F","A Foundation for the Composition of Multilevel Domain-Specific Languages","","2021","","","88–97","IEEE Press","Munich, Germany","Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems","","2021","9781728151250","","https://doi.org/10.1109/MODELS-C.2019.00018;http://dx.doi.org/10.1109/MODELS-C.2019.00018","10.1109/MODELS-C.2019.00018","In this paper, we provide a foundation for the definition and composition of multilevel domain-specific modelling languages. We will introduce modularization techniques such as composition, aggregation and referencing to enhance flexibility and reusability of these languages. To explain this foundation, we use Coloured Petri Nets (CPN) as a paradigmatic case study and define two CPN variants motivated by industrial collaboration projects: one used for the definition of protocols and the other one for robot controllers.","model-driven software engineering, coloured petri nets, multilevel modelling, model transformations","","MODELS '19"
"Conference Paper","Park B,Lee CG","System Optimization of ROS-Based Open Source Autonomous Driving Platform on Embedded Board Environment","","2023","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 6th International Conference on Algorithms, Computing and Systems","Larissa, Greece","2023","9781450397407","","https://doi.org/10.1145/3564982.3565000;http://dx.doi.org/10.1145/3564982.3565000","10.1145/3564982.3565000","The open-source robot operating system(ROS) is being studied in complex system such as autonomous driving. Many studies have made efforts to port real-time to ROS for complex systems based on ROS. However, these methods are not user-friendly because they are difficult to use and require complicated procedures. For that, we pay attention to the system's response time and explain how to reduce the response time. Finally, we reveal how much our approach improved ROS performance through experiments.","System Profiling, ROS, Optimization, Autonomous Driving","","ICACS '22"
"Conference Paper","Wen R,Han Z,Williams T","Teacher, Teammate, Subordinate, Friend: Generating Norm Violation Responses Grounded in Role-Based Relational Norms","","2022","","","353–362","IEEE Press","Sapporo, Hokkaido, Japan","Proceedings of the 2022 ACM/IEEE International Conference on Human-Robot Interaction","","2022","","","","","Language-capable robots require moral competence, including representations and algorithms for moral reasoning and moral communication. We argue for an ethical pluralist approach to moral competence that leverages and combines disparate ethical frameworks, and specifically argue for an approach to moral competence that is grounded not only in Deontological norms (as is typical in the HRI literature) but also in Confucian relational roles. To this end, we introduce the first computational approach that centers relational roles in moral reasoning and communication, and demonstrate the ability of this approach to generate both context-oriented and role-oriented explanations for robots' rejections of norm-violating commands, which we justify through our pluralist lens. Moreover, we provide the first investigation of how computationally generated role-based explanations are perceived by humans, and empirically demonstrate (N=120) that the effectiveness (in terms of of trust, understanding confidence, and perceived intelligence) of explanations grounded in different moral frameworks is dependent on nuanced mental modeling of human interlocutors.","moral communication, robot ethics, confucian ethics","","HRI '22"
"Conference Paper","Strait M,Urry HL,Muentener P","Children's Responding to Humanlike Agents Reflects an Uncanny Valley","","2020","","","506–515","IEEE Press","Daegu, Republic of Korea","Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction","","2020","9781538685556","","","","Both perceptual mechanisms (e.g., threat detection/avoidance) and social mechanisms (e.g., fears fostered via negative media) may explain the existence of the uncanny valley; however, existing literature lacks sufficient evidence to decide whether one, the other, or a combination best accounts for the valley's effects. As perceptually oriented explanations imply the valley should be evident early in development, we investigated whether it presents in the responding of children (N = 80; ages 5 --10) to agents of varying human similarity. We found that, like adults, children were most averse to highly humanlike robots (relative to less humanlike robots and humans). But, unlike adults, children's aversion did not translate to avoidance. The findings thus indicate, consistent with perceptual explanations, that the valley effect manifests well before adulthood. However, further research is needed to understand the emergence of the valley's behavioral consequences.","agency, uncanny valley, humanoids, cognitive development, child-robot interaction, anthropomorphism","","HRI '19"
"Conference Paper","Werkhoven P,Kester L,Neerincx M","Telling Autonomous Systems What to Do","","2018","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 36th European Conference on Cognitive Ergonomics","Utrecht, Netherlands","2018","9781450364492","","https://doi.org/10.1145/3232078.3232238;http://dx.doi.org/10.1145/3232078.3232238","10.1145/3232078.3232238","Recent progress in Artificial Intelligence, sensing and network technology, robotics, and (cloud) computing has enabled the development of intelligent autonomous machine systems. Telling such autonomous systems ""what to do"" in a responsible way, is a non-trivial task. For intelligent autonomous machines to function in human society and collaborate with humans, we see three challenges ahead affecting meaningful control of autonomous systems. First, autonomous machines are not yet capable of handling failures and unexpected situations. Providing procedures for all possible failures and situations is unfeasible because the state-action space would explode. Machines should therefore become self-aware (self-assessment, self-management) enabling them to handle unexpected situations when they arise. This is a challenge for the computer science community. Second, in order to keep (meaningful) control, humans come into a new role of providing intelligent autonomous machines with objectives or goal functions (including rules, norms, constraints and moral values), specifying the utility of every possible outcome of actions of autonomous machines. Third, in order to be able to collaborate with humans, autonomous systems will require an understanding of (us) humans (i.e., our social, cognitive, affective and physical behaviors) and the ability to engage in partnership interactions (such as explanations of task performances, and the establishment of joint goals and work agreements). These are new challenges for the cognitive ergonomics community.","autonomous systems, control, Cognitive ergonomics","","ECCE '18"
"Conference Paper","Qi X,Wang W,Liao Z,Zhang X,Xue L,Zhang X,Li J,Fang T,Wei R","Robot Teaching Assistant and Physical Programming Class for Programming Education of Young Children","","2021","","","55–62","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2020 1st International Conference on Control, Robotics and Intelligent System","Xiamen, China","2021","9781450388054","","https://doi.org/10.1145/3437802.3437812;http://dx.doi.org/10.1145/3437802.3437812","10.1145/3437802.3437812","This paper proposes a programming class for young children. In order to reduce the burden on teachers and attract students' interest, a robot teaching assistant is used to explain programming knowledge, verify and run programs. Different from writing programs on a computer, the physical board programming is employed to develop logical thinking of young children and prevent them from the vision harm of facing computer screens for a long time and the lack of reality from immersion in the virtual world. Based on the knowledge points of programming, we have designed a course with 16 lessons. The course has been successfully applied in many kindergartens and elementary schools. We use the questionnaires for students and teachers to evaluate the course and the experimental results show that it is effective.","Robot teaching assistant, Programming education, Physical programming","","CCRIS '20"
"Conference Paper","Hayakawa H,Fernando CL,Saraiji MY,Minamizawa K,Tachi S","Telexistence Drone: Design of a Flight Telexistence System for Immersive Aerial Sports Experience","","2015","","","171–172","Association for Computing Machinery","New York, NY, USA","Proceedings of the 6th Augmented Human International Conference","Singapore, Singapore","2015","9781450333498","","https://doi.org/10.1145/2735711.2735816;http://dx.doi.org/10.1145/2735711.2735816","10.1145/2735711.2735816","In this paper, a new sports genre, ""Aerial Sports"" is introduced where the humans and robots collaborate to enjoy space as a whole new field. By integrating a flight unit with the user's voluntary motion, everyone can enjoy the crossing physical limitations such as height and physique. The user can dive into the drone by wearing a HMD and experience the provided binocular stereoscopic visuals and sensation of flight using his limbs effectively. In this paper, the requirements and design steps for a Synchronization of visual information and physical motion in a flight system is explained mainly for aerial sports experience. The requirements explained in this paper can be also adapted to the purpose such as search and rescue or entertainment purposes where the coupled body motion has advantages.","augmented sports, virtual reality, drone telexistence, aerial sports, flight experience","","AH '15"
"Conference Paper","Watanabe H,Tanigawa I,Sugaya M,Ogura N,Hisazumi K","A Layer-Structure Diagram and a Layer-Interaction Diagram towards a Context-Oriented Development Methodology for Embedded Systems","","2016","","","125–130","Association for Computing Machinery","New York, NY, USA","Companion Proceedings of the 15th International Conference on Modularity","Málaga, Spain","2016","9781450340335","","https://doi.org/10.1145/2892664.2892685;http://dx.doi.org/10.1145/2892664.2892685","10.1145/2892664.2892685","The paper introduces new kinds of diagrams for describing organizations and interactions of layers based on context-oriented technology for context-sensitive embedded system developments. The concept of layers is suitable for processing context-aware embedded systems. As mentioned in several related literatures, layer-interactions cause critical problems such as deadlock, collision, and multi-invocation. To comprehend these problems at a high level, diagrams for visualizing relationships among layers are required. In a previous work, we proposed an OS-like architecture based on context-oriented technologies for embedded system development. The layering mechanism of the architecture dispatches or inserts layers with their states for dealing with layer-interaction problems. The goal of this paper is to introduce diagrams that contain notations for relating with the elements of the layering mechanism. To accomplish this, we consider the following issues: (1) the relations between layers, (2) layer-state management, and (3) context management attributes. The diagrams contribute to understanding layer-interaction problems with time delay and mutually exclusive layers. To explain the diagrams, we provide a simple example of an automatic cleaner robot.","Dynamic Program Rewriting, Context-Oriented Programing","","MODULARITY Companion 2016"
"Conference Paper","Karanasiou A,Pinotsis D","Towards a Legal Definition of Machine Intelligence: The Argument for Artificial Personhood in the Age of Deep Learning","","2017","","","119–128","Association for Computing Machinery","New York, NY, USA","Proceedings of the 16th Edition of the International Conference on Articial Intelligence and Law","London, United Kingdom","2017","9781450348911","","https://doi.org/10.1145/3086512.3086524;http://dx.doi.org/10.1145/3086512.3086524","10.1145/3086512.3086524","The paper dissects the intricacies of Automated Decision Making (ADM) and urges for refining the current legal definition of AI when pinpointing the role of algorithms in the advent of ubiquitous computing, data analytics and deep learning. ADM relies upon a plethora of algorithmic approaches and has already found a wide range of applications in marketing automation, social networks, computational neuroscience, robotics, and other fields. Our main aim here is to explain how a thorough understanding of the layers of ADM could be a first good step towards this direction: AI operates on a formula based on several degrees of automation employed in the interaction between the programmer, the user, and the algorithm; this can take various shapes and thus yield different answers to key issues regarding agency. The paper offers a fresh look at the concept of ""Machine Intelligence"", which exposes certain vulnerabilities in its current legal interpretation. Most importantly, it further helps us to explore whether the argument for ""artificial personhood"" holds any water. To highlight this argument, analysis proceeds in two parts: Part 1 strives to provide a taxonomy of the various levels of automation that reflects distinct degrees of Human - Machine interaction and can thus serve as a point of reference for outlining distinct rights and obligations of the programmer and the consumer: driverless cars are used as a case study to explore the several layers of human and machine interaction. These different degrees of automation reflect various levels of complexities in the underlying algorithms, and pose very interesting questions in terms of agency and dynamic tasks carried out by software agents. Part 2 further discusses the intricate nature of the underlying algorithms and artificial neural networks (ANN) that implement them and considers how one can interpret and utilize observed patterns in acquired data. Is ""artificial personhood"" a sufficient legal response to highly sophisticated machine learning techniques employed in decision making that successfully emulate or even enhance human cognitive abilities?","algorithmic agency, personhood hybrids, ANN, machine learning","","ICAIL '17"
"Conference Paper","Lee MJ,Ko AJ,Kwan I","In-Game Assessments Increase Novice Programmers' Engagement and Level Completion Speed","","2013","","","153–160","Association for Computing Machinery","New York, NY, USA","Proceedings of the Ninth Annual International ACM Conference on International Computing Education Research","San Diego, San California, USA","2013","9781450322430","","https://doi.org/10.1145/2493394.2493410;http://dx.doi.org/10.1145/2493394.2493410","10.1145/2493394.2493410","Assessments have been shown to have positive effects on learning in compulsory educational settings. However, much less is known about their effects in discretionary learning settings, especially in computing education and educational games. We hypothesized that adding assessments to an educational computing game would provide extra opportunities for players to practice and correct misconceptions, thereby affecting their performance on subsequent levels and their motivation to continue playing. To test this, we designed a game called Gidget, in which players help a robot find and fix defects in programs that follow a mastery learning paradigm. Across two studies, we manipulated the inclusion of multiple choice and self-explanation assessment levels in the game, measuring their impact on engagement and level completion speed. In our first study, we found that including assessments caused learners to voluntarily play longer and complete more levels, suggesting increased engagement; in our second study, we found that including assessments caused learners to complete levels faster, suggesting increased understanding. These findings suggest that including assessments in a discretionary computing education game may be a key design strategy for improving informal learning of computing concepts.","serious game, debugging, assessment, programming, engagement, educational game, speed","","ICER '13"
"Conference Paper","Salomons N,van der Linden M,Strohkorb Sebo S,Scassellati B","Humans Conform to Robots: Disambiguating Trust, Truth, and Conformity","","2018","","","187–195","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","Chicago, IL, USA","2018","9781450349536","","https://doi.org/10.1145/3171221.3171282;http://dx.doi.org/10.1145/3171221.3171282","10.1145/3171221.3171282","Asch's [2] conformity experiment has shown that people are prone to adjusting their view to match those of group members even when they believe the answer of the group to be wrong. Previous studies have attempted to replicate Asch's experiment with a group of robots but have failed to observe conformity [7, 25]. One explanation can be made using Hodges and Geyers work [17], in which they propose that people consider distinct criteria (truth, trust, and social solidarity) when deciding whether to conform to others. In order to study how trust and truth affect conformity, we propose an experiment in which participants play a game with three robots, in which there are no objective answers. We measured how many times participants changed their preliminary answers to match the group of robots' in their final answer. We conducted a between-subjects study (N = 30) in which there were two conditions: one in which participants saw the group of robots' preliminary answer before deciding their final answer, and a control condition in which they did not know the robots' preliminary answer. Participants in the experimental condition conformed significantly more (29%) than participants in the control condition (6%). Therefore we have shown that groups of robots can cause people to conform to them. Additionally trust plays a role in conformity: initially, participants conformed to robots at a similar rate to Asch's participants, however, many participants stop conforming later in the game when trust is lost due to the robots choosing an incorrect answer.","trust, human-robot groups, conformity","","HRI '18"
"Journal Article","Terwilliger MG,Jackson JL,Stenger CL,Jerkins JA","Using Computer Programming Activities and Robots to Teach Generalization of a Geometry Concept","J. Comput. Sci. Coll.","2019","34","3","82–90","Consortium for Computing Sciences in Colleges","Evansville, IN, USA","","","2019-01","","1937-4771","","","Computer science and math education researchers have long believed that a symbiotic relationship exists between their disciplines [7]. In fact, in its early days, computer science education programs were often co-located in a math department. Stenger et al. [13] developed an instructional treatment that uses computer programming as an explicit method for teaching abstraction and generalization in the STEM classroom. This instructional strategy uses computer programming to explore the essential characteristics of a mathematical concept and to push learners to advance in levels of abstraction. In this study, results are shown from a professional learning session using computer programming activities, mathematical arguments, and programming on an S2 robot to push middle and high school computer science, math, and science teachers (N=25) to improve their level of generalization over area expansion of a triangle with respect to the expansion of the sides of the triangle. The programming activities served as a laboratory to expose and explain what happened in the minds of learners as they explored and learned to generalize this geometry concept. The researchers used an initial genetic decomposition to evaluate the learner's level of abstraction. Follow up interviews were conducted with 6 participants. The analysis, using APOS as a framework, categorized mathematical behaviors at the Action, Process or Object level. The data demonstrated how computer programming activities influenced teachers' mental images and pushed them to higher levels of abstraction.","","",""
"Conference Paper","Zhao W,He T,Sani AY,Yao T","Review of SLAM Techniques For Autonomous Underwater Vehicles","","2019","","","384–389","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2019 International Conference on Robotics, Intelligent Control and Artificial Intelligence","Shanghai, China","2019","9781450372985","","https://doi.org/10.1145/3366194.3366262;http://dx.doi.org/10.1145/3366194.3366262","10.1145/3366194.3366262","Simultaneous Localization and Mapping (SLAM) is an important method for autonomous positioning and navigation of robots. SLAM application in underwater area has become an active field of research. Firstly, this paper presents the research status of SLAM technology follow by its application on underwater vehicles. Then, the implementation methods and main difficulties of underwater SLAM are explained. Finally, the research trend of underwater SLAM in the future is discussed.","Autonomous Navigation, Underwater Vehicle, Robot, Simultaneous Localization and Mapping (SLAM)","","RICAI '19"
"Conference Paper","Thomas MJ,Sudheer AP,Joy ML","Development of 4PRR-2P Hybrid Robotic System for Soft Material Cutting","","2017","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the Advances in Robotics","New Delhi, India","2017","9781450352949","","https://doi.org/10.1145/3132446.3134886;http://dx.doi.org/10.1145/3132446.3134886","10.1145/3132446.3134886","This paper deals with the development of a hybrid robotic system with lesser cost and minimum floor space area for cutting soft materials focusing on small scale industries. A waterjet cutting system was developed as the end effector for this hybrid manipulator. The main objective is to develop a multi-purpose manipulator for cutting softer materials such as soap, sponge, leather, rubber, pastry items etc. Many of the food manufacturing industries are producing unhygienic product that can be efficiently and correctly performed with computer controlled systems that operate automatically at faster speed. The design and fabrication of the 4PRR-2P robotic system with waterjet as the end effector is explained in this paper. The soft material chosen in this work is cake. Hence, the quality measures are met pertaining to food industries.","waterjet cutting, Workspace analysis, Kinematic Modelling (analytical approach), Parallel Kinematic Machines (PKM's)","","AIR '17"
"Conference Paper","Ping L","Enlightenment of Skill Competition to Training of High-Quality Applied Talents: Taking Industrial Robot Application in e-Commerce Logistics as an Example","","2020","","","39–43","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2020 Artificial Intelligence and Complex Systems Conference","Wuhan, China","2020","9781450377270","","https://doi.org/10.1145/3407703.3407712;http://dx.doi.org/10.1145/3407703.3407712","10.1145/3407703.3407712","Discipline competition is an important measure to test college teaching ability and students' application ability. Industry-education integration favors collaborative education in colleges and universities as well as training of high-quality applied talents. Based on discipline competition of local application-oriented colleges, this paper explains the role of skill competition in promoting in-depth integration of industry and education with application of industrial robots in the field of e-commerce logistics as an example, with a view to comprehensively promoting the transformation, upgrading and connotative development of application-oriented universities, so that they better serve local economic and social development.","industry-education integration, collaborative education, skill competition","","AICSconf '20"
"Conference Paper","Thalmann D,Thalmann NM","Interactive Virtual Characters","","2013","","","","Association for Computing Machinery","New York, NY, USA","SIGGRAPH Asia 2013 Courses","Hong Kong, Hong Kong","2013","9781450326315","","https://doi.org/10.1145/2542266.2542277;http://dx.doi.org/10.1145/2542266.2542277","10.1145/2542266.2542277","In this tutorial, we will describe both virtual characters and realistic humanoid social robots using the same high level models. Particularly, we will describe:1. How to capture real-time gestures and facial emotions from real people, how to recognize any real person, how to recognize certain sounds. We will present a state of the art and some new avenues of research.2. How to model a variety of interactive reactions of the virtual humans and social robots (facial expressions, gestures, multiparty dialog, etc) depending on the real scenes input parameters.3. How we can define Virtual Characters that have an emotional behavior (personality and mood and emotions) and how to allow them to remember us and have a believable relationship with us. This part is to allow virtual humans and social robots to have an individual and not automatic behaviour. This tutorial will also address the modelling of long-term and short-term memory and the interactions between users and virtual humans based on gaze and how to model visual attention. We will explain different methods to identify user actions and how to allow Virtual Characters to answer to them.4. This tutorial will also address the modelling of long-term and short-term memory and the interactions between users and virtual humans based on gaze and how to model visual attention. We will present the concepts of behavioral animation, group simulation, intercommunication between virtual humans, social humanoid robots and real people.Case studies will be presented from the Being There Centre (see http://imi.ntu.edu.sg/BeingThereCentre/Projects/Pages/Project4.aspx) where autonomous virtual humans and social robots react to a few actions from the real people.","","","SA '13"
"Conference Paper","Ross M,Broz F,Baillie L","Observing and Clustering Coaching Behaviours to Inform the Design of a Personalised Robotic Coach","","2021","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 23rd International Conference on Mobile Human-Computer Interaction","Toulouse & Virtual, France","2021","9781450383288","","https://doi.org/10.1145/3447526.3472043;http://dx.doi.org/10.1145/3447526.3472043","10.1145/3447526.3472043","Adherence to repetitive rehabilitation exercises is important in motor recovery after stroke. Similarly, repetitive solo practice exercises can improve the skill level of sports players. In both of these scenarios, regular human coaching has benefits, but in practice, the required training is often carried out alone, resulting in lowered adherence. This work presents a mixed methodology approach, novel in the context of designing for HRI, towards informing the design of a personalised robotic coach for stroke rehabilitation and squash. Using observations of human-human interactions, we first obtained action sequences of behaviours exhibited by coaches and physiotherapists. We then clustered these action sequences into behaviour graphs, with each graph representing a coaching policy usable for robotic control. Next we obtained coaches’ and physiotherapists’ reflections on the graphs’ applicability to the real world. Finally, we provide an explanation of how the policies visualised in these graphs could be used for robotic control.","HCI, Coaching, Stroke, Human Robot Interaction (HRI), Systematic observations","","MobileHCI '21"
"Conference Paper","McGinnis L,Buckley S,Barenji AV","Designing and Implementing Operational Controllers for a Robotic Tote Consolidation Cell Simulation","","2022","","","","IEEE Press","Phoenix, Arizona","Proceedings of the Winter Simulation Conference","","2022","","","","","Operational control is a key driver of production system performance, yet the design of operational controllers is not well-covered in the production systems simulation literature. With a robotic cell consolidating totes for delivery in a logistics hub as the use case, we describe the design of the cell's operational controller and an implementation approach used in an AnyLogic™ hybrid agent-discrete event simulation. Research motivation is discussed. Design principles are clearly explained, and key aspects of implementation for AnyLogic™ are presented. A companion Emulate3D™ model is described for obtaining realistic estimates of operation cycle times. Implications for the engineering of operational controllers in digital twins are addressed.","","","WSC '21"
"Conference Paper","Chen Y,Chen Z,Gumidyala S,Koures A,Lee S,Msekela J,Remash H,Schoenle N,Dahlby Albright S,Rebelsky SA","A Middle-School Code Camp Emphasizing Digital Humanities","","2019","","","351–357","Association for Computing Machinery","New York, NY, USA","Proceedings of the 50th ACM Technical Symposium on Computer Science Education","Minneapolis, MN, USA","2019","9781450358903","","https://doi.org/10.1145/3287324.3287509;http://dx.doi.org/10.1145/3287324.3287509","10.1145/3287324.3287509","Over the past decade, politicians, leaders, and pundits have called for computing and computer science education opportunities to be made available earlier and earlier. Such calls have led to the creation of a wide variety of offerings for students at middle-school and even elementary levels, including summer ""code camps"" targeted at middle-school students. Such camps often emphasize fun aspects of computing, such as games and robots. In contrast, research at the collegiate level suggests that meaningful applications of computing, such as computing for social good, are more successful at building and sustaining interest, particularly among students from groups traditionally underrepresented in computing. In this project, we developed and offered a summer camp that draws upon ideas and approaches from the digital humanities (DH), which explore the use of algorithms and computation in support of broader humanistic inquiry. Because DH reveals different ways to apply algorithmic and computational thinking, DH has the potential to attract students who might not otherwise consider computing. In this paper, we introduce central issues in the digital humanities, explain the rationale for the camp design, describe the camp curriculum, and reflect on successful and less successful aspects of the camp. Among other things, we consider how to introduce digital humanities topics to students who have not yet heard the term ""humanities"" and explore the utility of such topics for this age group. We also present preliminary data on the short-term effects of the camp on students' self-efficacy and interest in computing.","digital humanities, outreach (middle school), racket, code camp, natural language","","SIGCSE '19"
"Conference Paper","Dwarakanath TA,Bhutani G,Anubhav,Agrawal A","Spatial Remote Center Analysis of Parallel Robots","","2015","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2015 Conference on Advances In Robotics","Goa, India","2015","9781450333566","","https://doi.org/10.1145/2783449.2783455;http://dx.doi.org/10.1145/2783449.2783455","10.1145/2783449.2783455","Parallel manipulators have a wide range of motion capability characterized by their high precision, accuracy and speed. Their main limitation is of small workspaces. This paper presents the workspace analysis in a different perspective. It deals with combined translation and rotation workspace of platform of parallel mechanism. The paper gives an insight into creating spatial remote centers and their spherical ranges, which are critical for many robotic applications. A generalized approach for workspace analysis for parallel mechanism is presented. The geometrical scheme to obtain remote centre space for both planar and spatial parallel manipulators is explained. Real design examples of a 3 DOF Planar Parallel Kinematic Mechanism (PPKM) and a 6 DOF Parallel Kinematic Mechanism (6D PKM) are presented and are experimentally validated.","parallel mechanism, rotational workspace, spatial remote center, optimal pivot region","","AIR '15"
"Conference Paper","Ghiassian S,Rafiee B,Lo YL,White A","Improving Performance in Reinforcement Learning by Breaking Generalization in Neural Networks","","2020","","","438–446","International Foundation for Autonomous Agents and Multiagent Systems","Richland, SC","Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems","Auckland, New Zealand","2020","9781450375184","","","","Reinforcement learning systems require good representations to work well. For decades practical success in reinforcement learning was limited to small domains. Deep reinforcement learning systems, on the other hand, are scalable, not dependent on domain specific prior knowledge and have been successfully used to play Atari, in 3D navigation from pixels, and to control high degree of freedom robots. Unfortunately, the performance of deep reinforcement learning systems is sensitive to hyper-parameter settings and architecture choices. Even well tuned systems exhibit significant instability both within a trial and across experiment replications. In practice, significant expertise and trial and error are usually required to achieve good performance. One potential source of the problem is known as catastrophic interference: when later training decreases performance by overriding previous learning. Interestingly, the powerful generalization that makes Neural Networks (NN) so effective in batch supervised learning might explain the challenges when applying them in reinforcement learning tasks. In this paper, we explore how online NN training and interference interact in reinforcement learning. We find that simply re-mapping the input observations to a high-dimensional space improves learning speed and parameter sensitivity. We also show this preprocessing reduces interference in prediction tasks. More practically, we provide a simple approach to NN training that is easy to implement, and requires little additional computation. We demonstrate that our approach improves performance in both prediction and control with an extensive batch of experiments in classic control domains.","reinforcement learning, interference, neural networks","","AAMAS '20"
"Conference Paper","Salgian A,Nakra TM,Ault C,Wang Y","Teaching Creativity in Computer Science","","2013","","","123–128","Association for Computing Machinery","New York, NY, USA","Proceeding of the 44th ACM Technical Symposium on Computer Science Education","Denver, Colorado, USA","2013","9781450318686","","https://doi.org/10.1145/2445196.2445238;http://dx.doi.org/10.1145/2445196.2445238","10.1145/2445196.2445238","In this paper, we describe how a multidisciplinary undergraduate course in Conducting Robots becomes a venue for fostering creativity and teaching strategies for creativity enhancement. We perform a number of creativity measurements and explain our results in the context of creativity research.","orchestral conducting, robotics, multidisciplinary, music, creativity","","SIGCSE '13"
"Conference Paper","Tolmeijer S,Weiss A,Hanheide M,Lindner F,Powers TM,Dixon C,Tielman ML","Taxonomy of Trust-Relevant Failures and Mitigation Strategies","","2020","","","3–12","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction","Cambridge, United Kingdom","2020","9781450367462","","https://doi.org/10.1145/3319502.3374793;http://dx.doi.org/10.1145/3319502.3374793","10.1145/3319502.3374793","We develop a taxonomy that categorizes HRI failure types and their impact on trust to structure the broad range of knowledge contributions. We further identify research gaps in order to support fellow researchers in the development of trustworthy robots. Studying trust repair in HRI has only recently been given more interest and we propose a taxonomy of potential trust violations and suitable repair strategies to support researchers during the development of interaction scenarios. The taxonomy distinguishes four failure types: Design, System, Expectation, and User failures and outlines potential mitigation strategies. Based on these failures, strategies for autonomous failure detection and repair are presented, employing explanation, verification and validation techniques. Finally, a research agenda for HRI is outlined, discussing identified gaps related to the relation of failures and HR-trust.","trust violation, trust repair","","HRI '20"
"Conference Paper","Kuvent A,Maoz S,Ringert JO","A Symbolic Justice Violations Transition System for Unrealizable GR(1) Specifications","","2017","","","362–372","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering","Paderborn, Germany","2017","9781450351058","","https://doi.org/10.1145/3106237.3106240;http://dx.doi.org/10.1145/3106237.3106240","10.1145/3106237.3106240","One of the main challenges of reactive synthesis, an automated procedure to obtain a correct-by-construction reactive system, is to deal with unrealizable specifications. Existing approaches to deal with unrealizability, in the context of GR(1), an expressive assume-guarantee fragment of LTL that enables efficient synthesis, include the generation of concrete counter-strategies and the computation of an unrealizable core. Although correct, such approaches produce large and complicated counter-strategies, often containing thousands of states. This hinders their use by engineers. In this work we present the Justice Violations Transition System (JVTS), a novel symbolic representation of counter-strategies for GR(1). The JVTS is much smaller and simpler than its corresponding concrete counter-strategy. Moreover, it is annotated with invariants that explain how the counter-strategy forces the system to violate the specification. We compute the JVTS symbolically, and thus more efficiently, without the expensive enumeration of concrete states. Finally, we provide the JVTS with an on-demand interactive concrete and symbolic play. We implemented our work, validated its correctness, and evaluated it on 14 unrealizable specifications of autonomous Lego robots as well as on benchmarks from the literature. The evaluation shows not only that the JVTS is in most cases much smaller than the corresponding concrete counter-strategy, but also that its computation is faster.","reactive synthesis, GR(1), unrealizability","","ESEC/FSE 2017"
"Conference Paper","Cheon E,Su NM","Futuristic Autobiographies: Weaving Participant Narratives to Elicit Values around Robots","","2018","","","388–397","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction","Chicago, IL, USA","2018","9781450349536","","https://doi.org/10.1145/3171221.3171244;http://dx.doi.org/10.1145/3171221.3171244","10.1145/3171221.3171244","In this paper, we motivate and introduce Futuristic Autobiographies, a method inspired by design fiction for eliciting values and perspectives on the future of technologies from participants such as users, designers, and researchers. Futuristic autobiographies are the creative work of the researchers and participants. Grounded in empirical and background work, researchers pose several stories involving the participant as a character about a future state with robots. Participants are then asked to weave fictional autobiographies to explain what led to this future state. Via a case study in which futuristic autobiographies were used with 23 roboticists, we detail the process involved in developing and implementing this method. When futuristic autobiographies are employed and carefully crafted from background research, they allow informants to speak for themselves on how their practices and values are intertwined now and in the future. We highlight both the benefits and challenges of futuristic autobiographies as a way to elicit rich stories about values. We argue that futuristic autobiographies are a promising addition to the current qualitative methods toolkit used in HRI.","design fiction, qualitative methods, human-robot interaction, value sensitive design","","HRI '18"
"Conference Paper","Yang XJ,Unhelkar VV,Li K,Shah JA","Evaluating Effects of User Experience and System Transparency on Trust in Automation","","2017","","","408–416","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction","Vienna, Austria","2017","9781450343367","","https://doi.org/10.1145/2909824.3020230;http://dx.doi.org/10.1145/2909824.3020230","10.1145/2909824.3020230","Existing research assessing human operators' trust in automation and robots has primarily examined trust as a steady-state variable, with little emphasis on the evolution of trust over time. With the goal of addressing this research gap, we present a study exploring the dynamic nature of trust. We defined trust of entirety as a measure that accounts for trust across a human's entire interactive experience with automation, and first identified alternatives to quantify it using real-time measurements of trust. Second, we provided a novel model that attempts to explain how trust of entirety evolves as a user interacts repeatedly with automation. Lastly, we investigated the effects of automation transparency on momentary changes of trust. Our results indicated that trust of entirety is better quantified by the average measure of ""area under the trust curve"" than the traditional post-experiment trust measure. In addition, we found that trust of entirety evolves and eventually stabilizes as an operator repeatedly interacts with a technology. Finally, we observed that a higher level of automation transparency may mitigate the ""cry wolf"" effect -- wherein human operators begin to reject an automated system due to repeated false alarms.","supervisory control, trust in automation, automation transparency, long-term inter-actions","","HRI '17"
"Conference Paper","Chen J,Lin Z,Zhou S,Wen T,Zeng Q","A Meshfree Method for Deformation Field Reconstruction of Soft Tissue in Needle Insertion","","2022","","","45–53","Association for Computing Machinery","New York, NY, USA","Proceedings of the 2021 10th International Conference on Bioinformatics and Biomedical Science","Xiamen, China","2022","9781450384308","","https://doi.org/10.1145/3498731.3498738;http://dx.doi.org/10.1145/3498731.3498738","10.1145/3498731.3498738","Objective: The deformation field inside the soft tissue is useful to predict and track the specific target of needle insertion. Finite element (FE) provides a sensorless way to reconstruct the deformation field inside soft tissue. However, the time-consuming model meshing makes it difficult to automate the reconstruction during needle insertion operation. The purpose of this work is to present a numerical method that can automatically reconstruction of deformation field of large-deformed soft tissue during needle insertion. Methods: Reproducing kernel particle method (RKPM) was used to reconstruct the deformation and stress field of soft tissue with real-time acquired displacement and force boundary conditions. The tissue crack was simulated by employing a node split mechanism. The validation experiment involves puncturing a silicone phantom with a robotic arm integrated with a needle. Results: The reconstructed displacements approach the experimental measurements with the average error of 0.15mm, 0.30mm, 0.63mm, and 0.55mm respectively at 12mm, 24mm, 36mm, and 40mm insertion depths. The reconstructed data have respectively 88.9%, 50%, 16.7%, and 27.8% nodes with an absolute error of less than 0.3mm (2 pixels). The stress relaxation of the silicon model has been revealed and be used to qualitatively explain the reconstruction error. Von-mises stress field has been also presented and registered into the X-ray image. Conclusion: The proposed meshfree-based method has acceptable accuracy for reconstructing the deformation field inside the large-deformed organ.","soft tissue deformation, computational biomechanics, meshfree method, needle insertion","","ICBBS '21"
"Conference Paper","Jankauskis E,Elizondo S,Montano Murillo R,Marzo A,Martinez Plasencia D","TipTrap: A Co-Located Direct Manipulation Technique for Acoustically Levitated Content","","2022","","","","Association for Computing Machinery","New York, NY, USA","Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology","Bend, OR, USA","2022","9781450393201","","https://doi.org/10.1145/3526113.3545675;http://dx.doi.org/10.1145/3526113.3545675","10.1145/3526113.3545675","Acoustic levitation has emerged as a promising approach for mid-air displays, by using multiple levitated particles as 3D voxels, cloth and thread props, or high-speed tracer particles, under the promise of creating 3D displays that users can see, hear and feel with their bare eyes, ears and hands. However, interaction with this mid-air content always occurred at a distance, since external objects in the display volume (e.g. user’s hands) can disturb the acoustic fields and make the particles fall. This paper proposes TipTrap, a co-located direct manipulation technique for acoustically levitated particles. TipTrap leverages the reflection of ultrasound on the users’ skin and employs a closed-loop system to create functional acoustic traps 2.1 mm below the fingertips, and addresses its 3 basic stages: selection, manipulation and deselection. We use Finite-Differences Time Domain (FDTD) simulations to explain the principles enabling TipTrap, and explore how finger reflections and user strategies influence the quality of the traps (e.g. approaching direction, orientation and tracking errors), and use these results to design our technique. We then implement the technique, characterizing its performance with a robotic hand setup and finish with an exploration of the ability of TipTrap to manipulate different types of levitated content.","interaction techniques, co-located direct manipulation, spatial interaction, acoustic levitation","","UIST '22"
